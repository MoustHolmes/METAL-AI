{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_funcs\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "from ASF import ASF, Hyperparams\n",
    "import grasp\n",
    "# from dask.distributed import get_worker, Client, as_completed\n",
    "from tqdm import tqdm\n",
    "import simple_agent\n",
    "import result_types\n",
    "\n",
    "ryd_to_kelvin = 11606 * 13.605703976\n",
    "temp_kelvin=5000\n",
    "\n",
    "def process_result(added_index, tree, new_result, temp_kelvin=5000):\n",
    "\n",
    "    remove_slice = slice(*new_result[\"slices\"][added_index])\n",
    "\n",
    "    regularized = np.delete(new_result[\"eigenvectors\"], remove_slice,axis=1)\n",
    "    dist, _ = tree.query(regularized)\n",
    "    Ediff = new_result[\"eigenvalues\"] - new_result[\"eigenvalues\"][0]\n",
    "    bolzmann_factor = np.exp(-Ediff*ryd_to_kelvin/temp_kelvin)\n",
    "    effect_output = (dist*bolzmann_factor).sum()\n",
    "    return effect_output\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "with hdf5_funcs.ResultsLoader() as loader:\n",
    "    for asf, result_type, getter in loader.get_all_runs():\n",
    "        # excluding the starting point \n",
    "        if getter().initial_asf is not None:\n",
    "            \n",
    "            # creating thefilling numbers from the excitations and sorting them by the filling numbers\n",
    "            excitations = tuple(asf.excitations)\n",
    "            filling_numbers = (tuple(asf.to_filling_number(excitation)) for excitation in excitations)\n",
    "            filling_numbers, excitations   = zip(*sorted(zip( filling_numbers, excitations)))\n",
    "            \n",
    "            # using the number of electrons and protons together with the filling numbers as a key\n",
    "            # key = (asf.num_electrons, asf.num_protons, tuple(filling_numbers))\n",
    "            ion_key = (asf.num_protons, asf.num_electrons)\n",
    "            asf_key =  tuple(filling_numbers)\n",
    "            if ion_key not in data_dict:\n",
    "                data_dict[ion_key] = {}\n",
    "            if asf_key not in data_dict[ion_key]:\n",
    "                data_dict[ion_key][asf_key] = {}\n",
    "\n",
    "                # data_dict[key] = {}  # Initialize the dictionary for this key if it doesn't exist\n",
    "\n",
    "            # check if the result is converged or not and add the relevant information to the dictionary\n",
    "            if isinstance(getter(), result_types.ConvergedResult):\n",
    "                data_dict[ion_key][asf_key][\"excitations\"] = excitations\n",
    "                data_dict[ion_key][asf_key][\"index\"] = excitations.index(*(asf.excitations-getter().initial_asf.excitations))\n",
    "                data_dict[ion_key][asf_key][\"Converged\"] = True\n",
    "                # variables that are needed for the calculation of the effect and deleted later\n",
    "                data_dict[ion_key][asf_key][\"prev_asf\"] = getter().initial_asf\n",
    "                data_dict[ion_key][asf_key][\"eigenvalues\"] = getter().eigenvalues\n",
    "                data_dict[ion_key][asf_key][\"eigenvectors\"] = getter().eigenvectors\n",
    "                data_dict[ion_key][asf_key][\"slices\"] = getter().slices\n",
    "                # initialize the effect as array of nan with the length of the number of CSFs in the ASFs\n",
    "                data_dict[ion_key][asf_key][\"effect\"] = np.empty(len(asf_key))\n",
    "                data_dict[ion_key][asf_key][\"effect\"][:] = np.nan\n",
    "            \n",
    "\n",
    "            else :  # if isinstance(getter(), result_types.CrashedResult)\n",
    "                data_dict[ion_key][asf_key][\"excitations\"] = excitations\n",
    "                data_dict[ion_key][asf_key][\"index\"] = excitations.index(*(asf.excitations-getter().initial_asf.excitations))\n",
    "                data_dict[ion_key][asf_key][\"Converged\"] = False\n",
    "  \n",
    "# iterate over the dictionary and calculate the effect for each entry\n",
    "for ion_key, ion_dict in data_dict.items():\n",
    "    for asf_key, asf_dict in ion_dict.items():\n",
    "        if data_dict[ion_key][asf_key][\"Converged\"]:\n",
    "            prev_asf_with_index = (\n",
    "                (tuple(excitation for j, excitation in enumerate(sorted(tuple(asf_key))) if j != i), i)\n",
    "                for i in range(len(asf_key))\n",
    "            )\n",
    "\n",
    "            for prev_asf, i in prev_asf_with_index:\n",
    "                if prev_asf in ion_dict.keys():\n",
    "                    if ion_dict[prev_asf][\"Converged\"]:\n",
    "\n",
    "                        tree = scipy.spatial.KDTree(np.vstack([ion_dict[prev_asf][\"eigenvectors\"], -ion_dict[prev_asf][\"eigenvectors\"]]))\n",
    "                        ion_dict[asf_key][\"effect\"][i] = process_result(i, tree, ion_dict[asf_key])\n",
    "\n",
    "for ion_key, ion_dict in data_dict.items():\n",
    "    for asf_key, asf_dict in ion_dict.items():\n",
    "        # Remove \"eigenvalues\", \"eigenvectors\", \"prev_asf\", and \"slices\" from each entry\n",
    "        asf_dict.pop(\"eigenvalues\", None)\n",
    "        asf_dict.pop(\"eigenvectors\", None)\n",
    "        asf_dict.pop(\"prev_asf\", None)\n",
    "        asf_dict.pop(\"slices\", None)\n",
    "\n",
    "# for current_asf, current_asf_properties in data_dict.items():\n",
    "#     num_electrons, num_protons, filling_numbers = current_asf\n",
    "\n",
    "#     if current_asf_properties[\"Converged\"]:\n",
    "#         prev_asf_with_index = (\n",
    "#             ((num_electrons, num_protons, tuple(excitation for j, excitation in enumerate(sorted(tuple(filling_numbers))) if j != i)), i)\n",
    "#             for i in range(len(filling_numbers))\n",
    "#         )\n",
    "\n",
    "#         for prev_asf, i in prev_asf_with_index:\n",
    "#             if prev_asf in data_dict.keys():\n",
    "#                 if data_dict[prev_asf][\"Converged\"]:\n",
    "\n",
    "#                     tree = scipy.spatial.KDTree(np.vstack([data_dict[prev_asf][\"eigenvectors\"], -data_dict[prev_asf][\"eigenvectors\"]]))\n",
    "#                     data_dict[current_asf][\"effect\"][i] = process_result(i, tree, data_dict[current_asf])\n",
    "\n",
    "# for key in data_dict.keys():\n",
    "#     # Remove \"eigenvalues\", \"eigenvectors\", \"prev_asf\", and \"slices\" from each entry\n",
    "#     data_dict[key].pop(\"eigenvalues\", None)\n",
    "#     data_dict[key].pop(\"eigenvectors\", None)\n",
    "#     data_dict[key].pop(\"prev_asf\", None)\n",
    "#     data_dict[key].pop(\"slices\", None)\n",
    "\n",
    "import pickle\n",
    "filename = '/home/projects/ku_00258/people/mouhol/METAL-AI/data/Metal_data_dict_dataset/second_test_data_dict.pkl'\n",
    "\n",
    "# Use 'wb' to write in binary mode\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(data_dict, file)\n",
    "\n",
    "print(f'data_dict has been saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \n",
    "if a:\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "array_test= np.array([np.nan,True,False])\n",
    "for i in array_test:\n",
    "    if i:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in array_test:\n",
    "    if i==True:\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test= np.array([np.nan,np.nan,False])\n",
    "np.any(array_test==True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
