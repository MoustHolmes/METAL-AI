{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- dev\n",
      "train: true\n",
      "test: true\n",
      "ckpt_path: null\n",
      "seed: null\n",
      "data:\n",
      "  _target_: src.data.dict_datamodule.DictDataModule\n",
      "  data_dir: ${paths.data_dir}\n",
      "  batch_size: 16\n",
      "  train_val_splitter:\n",
      "    _target_: src.data.components.data_utils.TripleTrainValSplitter\n",
      "    validation_percentage: 0.05\n",
      "    ASF_size_percentage: 0.03\n",
      "    include_ion:\n",
      "    - - 21\n",
      "      - 21\n",
      "    - - 22\n",
      "      - 21\n",
      "    - - 23\n",
      "      - 21\n",
      "    - - 24\n",
      "      - 21\n",
      "    - - 22\n",
      "      - 22\n",
      "    - - 24\n",
      "      - 22\n",
      "    - - 25\n",
      "      - 22\n",
      "    - - 23\n",
      "      - 23\n",
      "    - - 24\n",
      "      - 23\n",
      "    - - 25\n",
      "      - 23\n",
      "    - - 26\n",
      "      - 23\n",
      "    - - 24\n",
      "      - 24\n",
      "    - - 25\n",
      "      - 24\n",
      "    - - 26\n",
      "      - 24\n",
      "    - - 27\n",
      "      - 24\n",
      "    unseen_ion:\n",
      "    - - 23\n",
      "      - 22\n",
      "    remove_nan_effect: false\n",
      "  num_workers: 0\n",
      "  shuffle: true\n",
      "  pin_memory: true\n",
      "  persistent_workers: false\n",
      "model:\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "    _partial_: true\n",
      "    T_0: 5\n",
      "    T_mult: 2\n",
      "    eta_min: 0.0\n",
      "  _target_: src.models.metalAI_module.MetalAILitModule\n",
      "  target_name: converged\n",
      "  model:\n",
      "    _target_: src.models.components.Transformer_encoder_model.simple_transformer_encoder_model\n",
      "    csf_encoder:\n",
      "      _target_: src.models.components.CSF_encoders.simple_CSF_encoder\n",
      "      output_size: 4\n",
      "    d_model: 32\n",
      "    nhead: 2\n",
      "    dim_forward: 16\n",
      "    num_layers: 4\n",
      "    output_size: 1\n",
      "    dropout: 0.0\n",
      "    output_activation:\n",
      "      _target_: torch.nn.Sigmoid\n",
      "  loss_fn:\n",
      "    _target_: src.models.components.loss_function_wrappers.LossFuncMaskWrapper\n",
      "    loss_fn:\n",
      "      _target_: torch.nn.BCELoss\n",
      "      reduction: sum\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.01\n",
      "  compile: false\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0.0\n",
      "    patience: 80\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: -1\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "logger:\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: MetalAI\n",
      "    log_model: false\n",
      "    prefix: ''\n",
      "    entity: MoustHolmes\n",
      "    group: ''\n",
      "    tags:\n",
      "    - convergence\n",
      "    - length_sorted_dataset\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 1\n",
      "  max_epochs: 5\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_dir: ${paths.root_dir}/data/data_dict_Li-Rh_new_effect.pkl\n",
      "  log_dir: ${paths.root_dir}/logs/\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext yamlmagic\n",
    "# %cd /Users/moustholmes/Projects/lightning-hydra-template\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Set the PROJECT_ROOT environment variable\n",
    "os.environ['PROJECT_ROOT'] = '/Users/moustholmes/Projects/METAL-AI'\n",
    "\n",
    "# Change the current working directory to the project root\n",
    "os.chdir('/Users/moustholmes/Projects/METAL-AI')\n",
    "\n",
    "# Initialize Hydra with the config path relative to the project root\n",
    "initialize(version_base=None, config_path='configs', job_name='notebook')\n",
    "\n",
    "cfg_train = compose(config_name='train',) #overrides=['experiment=effect_gaussian_nll'])\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_train = compose(config_name='train', overrides=['experiment=effect_gaussian_nll'])\n",
    "print(OmegaConf.to_yaml(cfg_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(cfg_train.data.data_dir, 'rb') as file:\n",
    "    data_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ion_key in data_dict.keys():\n",
    "    for asf_key in data_dict[ion_key].keys():\n",
    "        print(ion_key, asf_key)\n",
    "        pprint(data_dict[ion_key][asf_key])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /Users/moustholmes/Projects/METAL-AI/src/data/components/datasets.py\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class SimpleDictDataset(Dataset):\n",
    "    def __init__(self, data_dict, remove_nan_effect=False):\n",
    "        \"\"\"\n",
    "        data: The nested dictionary containing all your data\n",
    "        \"\"\"\n",
    "        self.data = data_dict\n",
    "        self.index_mapping = self._create_index_mapping(remove_nan_effect)\n",
    "\n",
    "    def _create_index_mapping(self, remove_nan_effect):\n",
    "        mapping = []\n",
    "        for ion_key in self.data.keys():\n",
    "            for asf_key in self.data[ion_key].keys():\n",
    "\n",
    "                data_point = self.data[ion_key][asf_key]\n",
    "\n",
    "                data_point[\"excitations\"] = torch.tensor(data_point[\"excitations\"])\n",
    "                data_point[\"converged_mask\"] = torch.from_numpy(\n",
    "                    ~np.isnan(data_point[\"converged\"])\n",
    "                )\n",
    "                data_point[\"converged\"] = torch.tensor(\n",
    "                    data_point[\"converged\"], dtype=torch.bool\n",
    "                )\n",
    "\n",
    "                if \"effect\" not in data_point:\n",
    "                    data_point[\"effect\"] = torch.full(\n",
    "                        (len(data_point[\"excitations\"]),), float(\"nan\")\n",
    "                    )\n",
    "                else:\n",
    "                    data_point[\"effect\"] = torch.tensor(data_point[\"effect\"])\n",
    "\n",
    "                data_point[\"n_protons\"] = torch.tensor(ion_key[0], dtype=torch.long)\n",
    "                data_point[\"n_electrons\"] = torch.tensor(ion_key[1], dtype=torch.long)\n",
    "\n",
    "                if remove_nan_effect:\n",
    "                    if \"effect\" not in self.data[ion_key][asf_key]:\n",
    "                        continue\n",
    "                    if np.isnan(self.data[ion_key][asf_key][\"effect\"]).all():\n",
    "                        continue\n",
    "                mapping.append((ion_key, asf_key))\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the actual keys from the index\n",
    "        ion_key, asf_key = self.index_mapping[idx]\n",
    "\n",
    "        data_point = self.data[ion_key][asf_key]\n",
    "\n",
    "        return data_point\n",
    "class GroupedDictDataset(Dataset):\n",
    "    def __init__(self, data_dict, remove_nan_effect=False, ion_include=None, ion_exclude=None):\n",
    "        self.data = data_dict\n",
    "        self.ion_include = ion_include\n",
    "        self.ion_exclude = ion_exclude\n",
    "        self.index_mapping = self._create_index_mapping(remove_nan_effect)\n",
    "        self.grouped_indices = self._group_by_excitations_length()\n",
    "\n",
    "    def _create_index_mapping(self, remove_nan_effect):\n",
    "        mapping = []\n",
    "        for ion_key in self.data.keys():\n",
    "            # Apply inclusion and exclusion filters\n",
    "            if self.ion_include is not None and ion_key not in self.ion_include:\n",
    "                continue\n",
    "            if self.ion_exclude is not None and ion_key in self.ion_exclude:\n",
    "                continue\n",
    "\n",
    "            for asf_key in self.data[ion_key].keys():\n",
    "                data_point = self.data[ion_key][asf_key]\n",
    "\n",
    "                if len(data_point[\"excitations\"]) == 1:\n",
    "                    continue\n",
    "\n",
    "                data_point[\"filling_numbers\"] = torch.tensor(asf_key)\n",
    "\n",
    "                if not isinstance(data_point[\"excitations\"], torch.Tensor):\n",
    "                    data_point[\"excitations\"] = torch.tensor(data_point[\"excitations\"])\n",
    "                \n",
    "                if not isinstance(data_point[\"converged\"], torch.Tensor):\n",
    "                    data_point[\"converged_mask\"] = torch.from_numpy(~np.isnan(data_point[\"converged\"]))\n",
    "                    data_point[\"converged\"] = torch.tensor(data_point[\"converged\"], dtype=torch.bool)\n",
    "\n",
    "                if not isinstance(data_point[\"effect\"], torch.Tensor):\n",
    "                    data_point[\"effect\"] = torch.tensor(data_point[\"effect\"], dtype=torch.float32)\n",
    "\n",
    "                data_point[\"n_protons\"] = torch.tensor(ion_key[0], dtype=torch.long)\n",
    "                data_point[\"n_electrons\"] = torch.tensor(ion_key[1], dtype=torch.long)\n",
    "\n",
    "                if remove_nan_effect:\n",
    "                    if \"effect\" not in data_point:\n",
    "                        continue\n",
    "                    if np.isnan(data_point[\"effect\"]).all():\n",
    "                        continue\n",
    "                mapping.append((ion_key, asf_key))\n",
    "\n",
    "        return mapping\n",
    "\n",
    "    def _group_by_excitations_length(self):\n",
    "        groups = {}\n",
    "        for idx, (ion_key, asf_key) in enumerate(self.index_mapping):\n",
    "            excitations_length = len(self.data[ion_key][asf_key][\"excitations\"])\n",
    "            if excitations_length == 1:\n",
    "                continue\n",
    "            if excitations_length not in groups:\n",
    "                groups[excitations_length] = []\n",
    "            groups[excitations_length].append(idx)\n",
    "        return groups\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ion_key, asf_key = self.index_mapping[idx]\n",
    "        data_point = self.data[ion_key][asf_key]\n",
    "\n",
    "        selected_data = {\n",
    "            'excitations': data_point['excitations'],\n",
    "            'filling_numbers': data_point['filling_numbers'],\n",
    "            'converged': data_point['converged'],\n",
    "            'converged_mask': data_point['converged_mask'],\n",
    "            'effect': data_point['effect'],\n",
    "            'n_protons': data_point['n_protons'],\n",
    "            'n_electrons': data_point['n_electrons'],\n",
    "        }\n",
    "        return selected_data\n",
    "\n",
    "        # return data_point\n",
    "        # return {\n",
    "        #     \"ion_key\": ion_key,\n",
    "        #     \"asf_key\": asf_key,\n",
    "        #     **data_point,  # Unpacking the data point into the returned dictionary\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GroupedDictDataset(data_dict,ion_include=[(4,4)],)\n",
    "print(len(dataset))\n",
    "for data in dataset:\n",
    "    pprint(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GroupedDictDataset(data_dict)\n",
    "# used_ex = [[0,0],[1, 0], [2, 0], [2, 1], [3, 0], [3, 1], [3, 2], [4, 0], [4, 1], [4, 2], [4, 3], [5, 0], [5, 1], [5, 2], [5, 3], [6, 0], [6, 1], [6, 2]]\n",
    "used_ex =  [(0, 0),\n",
    " (1, 0),\n",
    " (0, 1),\n",
    " (0, 2),\n",
    " (1, 1),\n",
    " (1, 2),\n",
    " (2, 1),\n",
    " (0, 3),\n",
    " (2, 2),\n",
    " (1, 3),\n",
    " (0, 4),\n",
    " (0, 5),\n",
    " (3, 2),\n",
    " (1, 4),\n",
    " (2, 3),\n",
    " (3, 3),\n",
    " (2, 4),\n",
    " (1, 5),\n",
    " (3, 4),\n",
    " (4, 3),\n",
    " (2, 5),\n",
    " (3, 5),\n",
    " (4, 4),\n",
    " (5, 4),\n",
    " (4, 5),\n",
    " (5, 5)]\n",
    "\n",
    "used_ex = [list(ex) for ex in used_ex]\n",
    "\n",
    "\n",
    "used_ex += [[0,0],[3, 4],[4,4],[3,3],[5,5],[5,4]]\n",
    "print(len(dataset))\n",
    "for data in dataset:\n",
    "    for i in range(data['excitations'].shape[0]):\n",
    "        if data['excitations'][i].tolist() not in used_ex:\n",
    "            print(data['excitations'][i].tolist())\n",
    "            # pprint(data)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /Users/moustholmes/Projects/METAL-AI/src/data/components/data_utils.py\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def load_data_dict(data_dir):\n",
    "    # Load the data dictionary from the data directory\n",
    "    with open(data_dir, \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def save_data_dict(data_dict, data_dir):\n",
    "    # Save the data dictionary to the data directory\n",
    "    with open(data_dir, \"wb\") as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "def top_asf_size_train_val_split(data_dict, validation_percentage=0.05):\n",
    "    # Flatten the data_dict to a list of tuples: (ion_key, asf_key, excitations_length)\n",
    "    flat_data = [\n",
    "        (ion_key, asf_key, len(data_dict[ion_key][asf_key][\"excitations\"]))\n",
    "        for ion_key in data_dict.keys()\n",
    "        for asf_key in data_dict[ion_key].keys()\n",
    "    ]\n",
    "\n",
    "    # Sort by the length of excitations in descending order\n",
    "    flat_data.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Determine the number of validation data points\n",
    "    validation_size = int(len(flat_data) * validation_percentage)\n",
    "\n",
    "    # Create the validation and training datasets\n",
    "    validation_data = {}\n",
    "    training_data = {}\n",
    "\n",
    "    # Add the top 5% to the validation set\n",
    "    for ion_key, asf_key, _ in flat_data[:validation_size]:\n",
    "        if ion_key not in validation_data:\n",
    "            validation_data[ion_key] = {}\n",
    "        validation_data[ion_key][asf_key] = data_dict[ion_key][asf_key]\n",
    "\n",
    "    # Add the remaining 95% to the training set\n",
    "    for ion_key, asf_key, _ in flat_data[validation_size:]:\n",
    "        if ion_key not in training_data:\n",
    "            training_data[ion_key] = {}\n",
    "        training_data[ion_key][asf_key] = data_dict[ion_key][asf_key]\n",
    "\n",
    "    return training_data, validation_data\n",
    "\n",
    "class TopASFSizeTrainValSplitter:\n",
    "    def __init__(self, validation_percentage: float = 0.05):\n",
    "        self.validation_percentage = validation_percentage\n",
    "\n",
    "    def __call__(self, data_dict):\n",
    "        return top_asf_size_train_val_split(data_dict, self.validation_percentage)\n",
    "\n",
    "def random_train_val_split(data_dict, validation_percentage=0.05):\n",
    "    # Flatten the data_dict to a list of tuples: (ion_key, asf_key)\n",
    "    flat_data = [\n",
    "        (ion_key, asf_key)\n",
    "        for ion_key in data_dict.keys()\n",
    "        for asf_key in data_dict[ion_key].keys()\n",
    "    ]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Shuffle the data randomly\n",
    "    random.shuffle(flat_data)\n",
    "    \n",
    "    # Determine the number of validation data points\n",
    "    validation_size = int(len(flat_data) * validation_percentage)\n",
    "    \n",
    "    # Create the validation and training datasets\n",
    "    validation_data = {}\n",
    "    training_data = {}\n",
    "    \n",
    "    # Add the first part to the validation set\n",
    "    for ion_key, asf_key in flat_data[:validation_size]:\n",
    "        if ion_key not in validation_data:\n",
    "            validation_data[ion_key] = {}\n",
    "        validation_data[ion_key][asf_key] = data_dict[ion_key][asf_key]\n",
    "    \n",
    "    # Add the remaining part to the training set\n",
    "    for ion_key, asf_key in flat_data[validation_size:]:\n",
    "        if ion_key not in training_data:\n",
    "            training_data[ion_key] = {}\n",
    "        training_data[ion_key][asf_key] = data_dict[ion_key][asf_key]\n",
    "    \n",
    "    return training_data, validation_data\n",
    "\n",
    "class RandomTrainValSplitter:\n",
    "    def __init__(self, validation_percentage: float = 0.05):\n",
    "        self.validation_percentage = validation_percentage\n",
    "\n",
    "    def __call__(self, data_dict):\n",
    "        return random_train_val_split(data_dict, self.validation_percentage)\n",
    "\n",
    "def triple_train_val_split(\n",
    "    data_dict, \n",
    "    validation_percentage=0.05,\n",
    "    ASF_size_percentage=0.05,\n",
    "    include_ion=None,\n",
    "    unseen_ion=None,\n",
    "    remove_nan_effect=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Split data into:\n",
    "    - `training_data`: Remaining training data after validation splits.\n",
    "    - `validation_data`: Random subset for validation from training ions.\n",
    "    - `unseen_data`: Data belonging to unseen ions (not part of include_ion).\n",
    "    - `large_data`: ASFs larger than the calculated thresholds.\n",
    "    \"\"\"\n",
    "\n",
    "    include_ion = [tuple(item) for item in include_ion] if include_ion else None\n",
    "    unseen_ion = [tuple(item) for item in unseen_ion] if unseen_ion else None\n",
    "\n",
    "    # Step 1: Calculate thresholds for large ASFs for each ion\n",
    "    ion_threshold = {}\n",
    "    for ion_key in data_dict.keys():\n",
    "        # Get all ASF sizes for this ion, applying `remove_nan_effect` if True\n",
    "        asf_sizes = [\n",
    "            len(asf_data[\"excitations\"])\n",
    "            for asf_key, asf_data in data_dict[ion_key].items()\n",
    "            if not (remove_nan_effect and (\"effect\" not in asf_data or np.isnan(asf_data[\"effect\"]).all()))\n",
    "        ]\n",
    "        if not asf_sizes:  # If no valid ASFs remain, skip this ion\n",
    "            ion_threshold[ion_key] = float('inf')  # No ASFs qualify\n",
    "            continue\n",
    "        # Sort ASF sizes in descending order\n",
    "        asf_sizes.sort(reverse=True)\n",
    "        # Calculate the threshold index\n",
    "        threshold_index = max(0, int(len(asf_sizes) * ASF_size_percentage) - 1)\n",
    "        # Determine the threshold size\n",
    "        ion_threshold[ion_key] = asf_sizes[threshold_index]\n",
    "\n",
    "    # Step 2: Initialize splits\n",
    "    training_data = {}\n",
    "    validation_data = {}\n",
    "    unseen_data = {}\n",
    "    large_data = {}\n",
    "\n",
    "    # Step 3: Assign data points to the correct sets\n",
    "    for ion_key, asfs in data_dict.items():\n",
    "        for asf_key, asf_data in asfs.items():\n",
    "            if remove_nan_effect:\n",
    "                    if \"effect\" not in asf_data:\n",
    "                        continue\n",
    "                    if np.isnan(asf_data[\"effect\"]).all():\n",
    "                        continue\n",
    "            asf_size = len(asf_data[\"excitations\"])\n",
    "            above_threshold = asf_size >= ion_threshold[ion_key]\n",
    "\n",
    "            # Check if ion belongs to unseen_ion\n",
    "            if unseen_ion is not None and ion_key in unseen_ion:\n",
    "                if not above_threshold:\n",
    "                    if ion_key not in unseen_data:\n",
    "                        unseen_data[ion_key] = {}\n",
    "                    unseen_data[ion_key][asf_key] = asf_data\n",
    "            # Include ions in training or validation\n",
    "            elif include_ion is None or ion_key in include_ion:\n",
    "                if above_threshold:\n",
    "                    if ion_key not in large_data:\n",
    "                        large_data[ion_key] = {}\n",
    "                    large_data[ion_key][asf_key] = asf_data\n",
    "                else:\n",
    "                    if ion_key not in training_data:\n",
    "                        training_data[ion_key] = {}\n",
    "                    training_data[ion_key][asf_key] = asf_data\n",
    "\n",
    "    # Step 4: Randomly split training_data into training and validation subsets\n",
    "    flat_training_data = [\n",
    "        (ion_key, asf_key)\n",
    "        for ion_key, asfs in training_data.items()\n",
    "        for asf_key in asfs.keys()\n",
    "    ]\n",
    "    random.shuffle(flat_training_data)\n",
    "    validation_size = int(len(flat_training_data) * validation_percentage)\n",
    "    validation_subset = flat_training_data[:validation_size]\n",
    "\n",
    "    final_training_data = {}\n",
    "    for ion_key, asf_key in flat_training_data[validation_size:]:\n",
    "        if ion_key not in final_training_data:\n",
    "            final_training_data[ion_key] = {}\n",
    "        final_training_data[ion_key][asf_key] = training_data[ion_key][asf_key]\n",
    "\n",
    "    for ion_key, asf_key in validation_subset:\n",
    "        if ion_key not in validation_data:\n",
    "            validation_data[ion_key] = {}\n",
    "        validation_data[ion_key][asf_key] = training_data[ion_key][asf_key]\n",
    "\n",
    "    return final_training_data, validation_data, unseen_data, large_data\n",
    "\n",
    "class TripleTrainValSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        validation_percentage: float = 0.05,\n",
    "        ASF_size_percentage: float = 0.05,\n",
    "        include_ion=None,\n",
    "        unseen_ion=None,\n",
    "        remove_nan_effect=False,\n",
    "    ):\n",
    "        self.validation_percentage = validation_percentage\n",
    "        self.ASF_size_percentage = ASF_size_percentage\n",
    "        self.include_ion = include_ion\n",
    "        self.unseen_ion = unseen_ion\n",
    "        self.remove_nan_effect = remove_nan_effect\n",
    "\n",
    "    def __call__(self, data_dict):\n",
    "        return triple_train_val_split(\n",
    "            data_dict,\n",
    "            self.validation_percentage,\n",
    "            self.ASF_size_percentage,\n",
    "            self.include_ion,\n",
    "            self.unseen_ion,\n",
    "            self.remove_nan_effect,\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_val_splitter = TopASFSizeTrainValSplitter()\n",
    "train_val_splitter = RandomTrainValSplitter()\n",
    "\n",
    "data_dict_train, data_dict_val = train_val_splitter(data_dict)\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True, ion_include=[(4,4)])\n",
    "dataset_train = GroupedDictDataset( data_dict_train, remove_nan_effect=True, ion_include=[(4,4)])\n",
    "dataset_val = GroupedDictDataset( data_dict_val, remove_nan_effect=True, ion_include=[(4,4)])\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(22,22),\n",
    "# (24,22),\n",
    "# (25,22),\n",
    "# (23,23),\n",
    "# (24,23),\n",
    "# (25,23),\n",
    "# (26,23),]\n",
    "\n",
    "\n",
    "triple_train_val_splitter = TripleTrainValSplitter( \n",
    "    validation_percentage=0.2,\n",
    "    ASF_size_percentage=0.05, \n",
    "    include_ion = [\n",
    "        (22,22),\n",
    "        (24,22),\n",
    "        (25,22),\n",
    "        (23,23),\n",
    "        (24,23),\n",
    "        (25,23),\n",
    "        (26,23),\n",
    "        ], \n",
    "    unseen_ion =[\n",
    "        (23,22)\n",
    "        ],\n",
    "    remove_nan_effect=True\n",
    "    \n",
    "    )\n",
    "data_dict_train, data_dict_val, data_dict_unseen, data_dict_large = triple_train_val_splitter(data_dict)\n",
    "dataset_train = GroupedDictDataset(data_dict_train, remove_nan_effect=False)\n",
    "dataset_val = GroupedDictDataset(data_dict_val, remove_nan_effect=False)\n",
    "dataset_unseen = GroupedDictDataset(data_dict_unseen, remove_nan_effect=False)\n",
    "dataset_large = GroupedDictDataset(data_dict_large, remove_nan_effect=False)\n",
    "\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_val))\n",
    "print(len(dataset_unseen))\n",
    "print(len(dataset_large))\n",
    "# print(len(dataset_val)/(len(dataset_val) +len(dataset_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /Users/moustholmes/Projects/METAL-AI/src/data/components/collate_fns.py\n",
    "import torch\n",
    "\n",
    "def dict_collate_fn(batch):\n",
    "    # Find the maximum number of 'CSFs' across all samples in the batch.\n",
    "    max_csf_count = max([len(item[\"excitations\"]) for item in batch])\n",
    "\n",
    "    # Initialize lists to hold padded 'CSFs' and the original lengths.\n",
    "    original_lengths = []\n",
    "\n",
    "    padded_csfs_list = []\n",
    "    padded_converged_list = []\n",
    "    padded_converged_mask_list = []\n",
    "    padded_effect_list = []\n",
    "\n",
    "    for item in batch:\n",
    "        original_length = item[\"excitations\"].size(0)\n",
    "        original_lengths.append(original_length)\n",
    "        padded_csfs = torch.cat(\n",
    "            [\n",
    "                item[\"excitations\"],\n",
    "                torch.zeros(max_csf_count - original_length, 2),  # change the 2 to the number of allowed excitations\n",
    "            ]\n",
    "        )\n",
    "        # print(item['converged'])\n",
    "        padded_converged = torch.cat(\n",
    "            [\n",
    "                item[\"converged\"],\n",
    "                torch.zeros(\n",
    "                    max_csf_count - original_length,\n",
    "                ),  # Pad with zeros. dtype=torch.bool\n",
    "            ]\n",
    "        )\n",
    "        padded_converged_mask = torch.cat(\n",
    "            [\n",
    "                item[\"converged_mask\"],\n",
    "                torch.zeros(\n",
    "                    max_csf_count - original_length,\n",
    "                ),  # Pad with zeros. dtype=torch.bool\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        padded_effect = torch.cat(\n",
    "            [\n",
    "                item[\"effect\"],\n",
    "                torch.zeros(max_csf_count - original_length),  # Pad with zeros.\n",
    "            ]\n",
    "        )\n",
    "        padded_csfs_list.append(padded_csfs)\n",
    "        padded_converged_list.append(padded_converged)\n",
    "        padded_converged_mask_list.append(padded_converged_mask)\n",
    "        padded_effect_list.append(padded_effect)\n",
    "\n",
    "    # Stack the padded 'CSFs'.\n",
    "    padded_csfs = torch.stack(padded_csfs_list)\n",
    "    padded_converged = torch.stack(padded_converged_list)\n",
    "    padded_converged_mask = torch.stack(padded_converged_mask_list)\n",
    "    padded_effect = torch.stack(padded_effect_list)\n",
    "\n",
    "    # Create a mask based on the original lengths.\n",
    "    mask = torch.ones_like(padded_csfs[:, :, 0], dtype=torch.bool)\n",
    "    for i, length in enumerate(original_lengths):\n",
    "        mask[i, :length] = False\n",
    "\n",
    "    # Convert other attributes to tensors.\n",
    "    n_electrons = torch.stack([item[\"n_electrons\"] for item in batch])\n",
    "    n_protons = torch.stack([item[\"n_protons\"] for item in batch])\n",
    "\n",
    "    # Return a dictionary with the batched data and the mask.\n",
    "    return {\n",
    "        \"excitations\": padded_csfs,\n",
    "        \"pad_mask\": mask,\n",
    "        \"n_electrons\": n_electrons,\n",
    "        \"n_protons\": n_protons,\n",
    "        \"converged\": padded_converged,\n",
    "        \"converged_mask\": padded_converged_mask,\n",
    "        \"effect\": padded_effect,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/data/components/samplers.py\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "# class GroupedBatchSampler(Sampler):\n",
    "#     def __init__(self, dataset, batch_size, shuffle=True):\n",
    "#         self.dataset = dataset\n",
    "#         self.batch_size = batch_size\n",
    "#         self.grouped_indices = dataset.grouped_indices\n",
    "#         if shuffle:\n",
    "#             self.group_lengths = sorted(self.grouped_indices.keys())\n",
    "#         else:\n",
    "#             self.group_lengths = list(self.grouped_indices.keys())\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         for length in self.group_lengths:\n",
    "#             indices = self.grouped_indices[length]\n",
    "#             random.shuffle(indices)\n",
    "#             # Yield full batches only\n",
    "#             for i in range(0, len(indices), self.batch_size):\n",
    "#                 if i + self.batch_size <= len(indices):\n",
    "#                     yield indices[i:i + self.batch_size]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         # This is an approximation, as we drop the last incomplete batch in each group\n",
    "#         return sum(len(indices) // self.batch_size for indices in self.grouped_indices.values())\n",
    "\n",
    "class GroupedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.grouped_indices = dataset.grouped_indices\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        all_batches = []\n",
    "\n",
    "        # Sort the group lengths if shuffle is False\n",
    "        group_lengths = sorted(self.grouped_indices.keys()) if not self.shuffle else list(self.grouped_indices.keys())\n",
    "\n",
    "        for length in group_lengths:\n",
    "            indices = self.grouped_indices[length]\n",
    "            # Shuffle within each group if shuffle is True\n",
    "            if self.shuffle:\n",
    "                random.shuffle(indices)\n",
    "            \n",
    "            # Form batches from the indices of this group\n",
    "            for i in range(0, len(indices), self.batch_size):\n",
    "                if i + self.batch_size <= len(indices):\n",
    "                    all_batches.append(indices[i:i + self.batch_size])\n",
    "\n",
    "        # Shuffle all batches if shuffle is True\n",
    "        if self.shuffle:\n",
    "            random.shuffle(all_batches)\n",
    "\n",
    "        # Yield each batch one by one\n",
    "        for batch in all_batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        # This is an approximation, as we drop the last incomplete batch in each group\n",
    "        return sum(len(indices) // self.batch_size for indices in self.grouped_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "# sampler = GroupedBatchSampler(dataset, batch_size=cfg_train.data.batch_size)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=dict_collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['excitations'].shape[1])\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "# sampler = GroupedBatchSampler(dataset, batch_size=cfg_train.data.batch_size)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=dict_collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=cfg_train.data.batch_size)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['excitations'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=cfg_train.data.batch_size)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler, collate_fn=dict_collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch['excitations'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "splitter = RandomTrainValSplitter(0.5)\n",
    "\n",
    "train_data_dict, val_data_dict = splitter(data_dict)\n",
    "\n",
    "train_dataset = GroupedDictDataset( train_data_dict, remove_nan_effect=True)\n",
    "val_dataset = GroupedDictDataset( val_data_dict, remove_nan_effect=True)\n",
    "\n",
    "train_sampler = GroupedBatchSampler(train_dataset, batch_size=cfg_train.data.batch_size, shuffle = True)\n",
    "val_sampler = GroupedBatchSampler(val_dataset, batch_size=cfg_train.data.batch_size,shuffle = True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_sampler=val_sampler)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(batch['excitations'].shape[1])\n",
    "\n",
    "\n",
    "print()\n",
    "print('val!!!')\n",
    "print()\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    print(batch['excitations'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/models/components/CSF_encoders.py\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class simple_CSF_encoder(nn.Module):\n",
    "    def __init__(self, output_size=32):\n",
    "        super(simple_CSF_encoder, self).__init__()\n",
    "        # Assuming the input size is 6 because we append n_electrons (1) and n_protons (1) to each 4-dimensional CSF.\n",
    "        self.output_size = output_size\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(4, 64), # number of allowed excitations + 2\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        excitations = input_dict[\"excitations\"]\n",
    "        n_electrons = input_dict[\"n_electrons\"]\n",
    "        n_protons = input_dict[\"n_protons\"]\n",
    "\n",
    "        # Append n_electrons and n_protons to each excitations\n",
    "        n_electrons = n_electrons.float().unsqueeze(-1).unsqueeze(-1).expand(-1, excitations.size(1), 1)\n",
    "        n_protons = n_protons.float().unsqueeze(-1).unsqueeze(-1).expand(-1, excitations.size(1), 1)\n",
    "        extended_excitations = torch.cat([excitations, n_electrons, n_protons], dim=-1)\n",
    "        return self.network(extended_excitations)\n",
    "    \n",
    "class no_CSF_encoder(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(simple_CSF_encoder, self).__init__()\n",
    "        # Assuming the input size is 6 because we append n_electrons (1) and n_protons (1) to each 4-dimensional CSF.\n",
    "\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "\n",
    "        excitations = input_dict[\"excitations\"]\n",
    "        n_electrons = input_dict[\"n_electrons\"]\n",
    "        n_protons = input_dict[\"n_protons\"]\n",
    "\n",
    "        # Append n_electrons and n_protons to each CSF\n",
    "        \n",
    "        n_electrons = n_electrons.float().unsqueeze(-1).unsqueeze(-1).expand(-1, excitations.size(1), 1)\n",
    "        n_protons = n_protons.float().unsqueeze(-1).unsqueeze(-1).expand(-1, excitations.size(1), 1)\n",
    "        extended_excitations = torch.cat([excitations, n_electrons, n_protons], dim=-1)\n",
    "        return extended_excitations\n",
    "\n",
    "class RotaryEmbedding2Angle4D(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        \"\"\"\n",
    "        Initialize the RepeatedRotaryEmbedding module.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the embeddings, must be divisible by 4.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 4 == 0, \"Embedding dimension must be divisible by 4\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, embeddings, theta, phi):\n",
    "        \"\"\"\n",
    "        Applies the repeated rotation on the embeddings using angles theta and phi.\n",
    "\n",
    "        Args:\n",
    "            embeddings (torch.Tensor): Input embeddings of shape [batch_size, n, dim].\n",
    "            theta (torch.Tensor): Rotation angles for xy planes of shape [batch_size].\n",
    "            phi (torch.Tensor): Rotation angles for zw planes of shape [batch_size].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Rotated embeddings of the same shape as input.\n",
    "        \"\"\"\n",
    "        batch_size, n, dim = embeddings.shape\n",
    "        assert dim == self.dim, f\"Input embedding dimension {dim} does not match initialized dimension {self.dim}\"\n",
    "\n",
    "        num_blocks = dim // 4  # Number of 4x4 blocks per embedding\n",
    "\n",
    "        # Compute rotation components\n",
    "        cos_theta = torch.cos(theta).unsqueeze(1).repeat(1, num_blocks)  # Shape: [batch_size, num_blocks]\n",
    "        sin_theta = torch.sin(theta).unsqueeze(1).repeat(1, num_blocks)  # Shape: [batch_size, num_blocks]\n",
    "        cos_phi = torch.cos(phi).unsqueeze(1).repeat(1, num_blocks)      # Shape: [batch_size, num_blocks]\n",
    "        sin_phi = torch.sin(phi).unsqueeze(1).repeat(1, num_blocks)      # Shape: [batch_size, num_blocks]\n",
    "\n",
    "        # Create block-diagonal rotation matrix for the entire batch\n",
    "        R = torch.zeros(batch_size, dim, dim, device=embeddings.device)\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            # Define indices for the i-th block\n",
    "            start = i * 4\n",
    "            end = start + 4\n",
    "\n",
    "            # Fill the block-diagonal matrix for all batches\n",
    "            R[:, start:start+2, start:start+2] = torch.stack([\n",
    "                torch.stack([cos_theta[:, i], -sin_theta[:, i]], dim=-1),\n",
    "                torch.stack([sin_theta[:, i], cos_theta[:, i]], dim=-1)\n",
    "            ], dim=1)\n",
    "\n",
    "            R[:, start+2:end, start+2:end] = torch.stack([\n",
    "                torch.stack([cos_phi[:, i], -sin_phi[:, i]], dim=-1),\n",
    "                torch.stack([sin_phi[:, i], cos_phi[:, i]], dim=-1)\n",
    "            ], dim=1)\n",
    "\n",
    "        # Apply the rotation to embeddings\n",
    "        rotated_embeddings = torch.einsum('bnd,bdm->bnm', embeddings, R)\n",
    "\n",
    "        return rotated_embeddings\n",
    "\n",
    "class PairEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, pair_list=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_dim (int): Dimension of the embedding.\n",
    "            pair_list (list of tuples): List of unique (x, y) pairs to index.\n",
    "        \"\"\"\n",
    "        super(PairEmbedding, self).__init__()\n",
    "        if pair_list is None:\n",
    "            pair_list = [\n",
    "                (0, 0), (1, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 1),\n",
    "                (0, 3), (2, 2), (1, 3), (0, 4), (0, 5), (3, 2), (1, 4),\n",
    "                (2, 3), (3, 3), (2, 4), (1, 5), (3, 4), (4, 3), (2, 5),\n",
    "                (3, 5), (4, 4), (5, 4), (4, 5), (5, 5)\n",
    "            ]\n",
    "        \n",
    "        # Initialize the embedding layer\n",
    "        self.embedding = nn.Embedding(len(pair_list), embedding_dim)\n",
    "        \n",
    "        # Create the lookup table\n",
    "        self.max_val = max(max(pair) for pair in pair_list)\n",
    "        lookup_table = torch.full((self.max_val + 1, self.max_val + 1), -1, dtype=torch.long)\n",
    "        for idx, pair in enumerate(pair_list):\n",
    "            lookup_table[pair[0], pair[1]] = idx\n",
    "        \n",
    "        # Register the lookup table as a buffer so it moves with the module\n",
    "        self.register_buffer(\"lookup_table\", lookup_table, persistent=True)\n",
    "\n",
    "    def forward(self, pair_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pair_tensor (torch.Tensor): Tensor of shape [batch_size, n, 2] containing pairs.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Embedding tensor of shape [batch_size, n, embedding_dim].\n",
    "        \"\"\"\n",
    "        # Use the lookup table to find indices for all pairs in the batch\n",
    "        indices = self.lookup_table[pair_tensor[..., 0], pair_tensor[..., 1]]\n",
    "        \n",
    "        # Pass the indices to the embedding layer\n",
    "        embedded = self.embedding(indices)  # This will be of shape [batch_size, n, embedding_dim]\n",
    "        return embedded\n",
    "\n",
    "\n",
    "\n",
    "class ExcitaionEmbeddingIonRoPE(nn.Module):\n",
    "    def __init__(self, output_size, angle_scale=0.05):\n",
    "        super(ExcitaionEmbeddingIonRoPE, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.angle_scale = angle_scale\n",
    "\n",
    "        self.excitation_embedding = PairEmbedding(embedding_dim=output_size)\n",
    "        self.ion_rope = RotaryEmbedding2Angle4D(dim=output_size)\n",
    "s\n",
    "    def forward(self, input_dict):\n",
    "        excitations = input_dict[\"excitations\"]\n",
    "        n_electrons = input_dict[\"n_electrons\"]\n",
    "        n_protons = input_dict[\"n_protons\"]\n",
    "\n",
    "\n",
    "        # Embed the excitations\n",
    "        embedded_excitations = self.excitation_embedding(excitations)\n",
    "\n",
    "        # rotary positional encoding for the ions\n",
    "        embedding = self.ion_rope(embedded_excitations, n_electrons * self.angle_scale, n_protons * self.angle_scale)\n",
    "\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer_encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/models/components/Transformer_encoder_model.py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, Optional\n",
    "\n",
    "\n",
    "class simple_transformer_encoder_model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csf_encoder,\n",
    "        input_size: int = 4, # number of allowed excitations + 2\n",
    "        d_model: int = 64,\n",
    "        nhead: int = 8,\n",
    "        dim_forward: int = 64,\n",
    "        num_layers: int = 6,\n",
    "        output_size: int =1,\n",
    "        dropout: float = 0.5,\n",
    "        output_activation: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n",
    "    ):\n",
    "        super(simple_transformer_encoder_model, self).__init__()\n",
    "        self.csf_encoder = csf_encoder\n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            self.csf_encoder.output_size, nhead, dim_forward, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(self.csf_encoder.output_size, output_size)\n",
    "        self.output_activation = output_activation\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        encoded_csfs = self.csf_encoder(input_dict)\n",
    "        output = self.transformer_encoder(encoded_csfs)#,src_key_padding_mask = input_dict['pad_mask']  src_key_padding_mask = ~input_dict['mask']\n",
    "        # output = output[:, 0, :]\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        if self.output_activation:\n",
    "            output = self.output_activation(output)\n",
    "\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "\n",
    "        # csfs = input_dict[\"excitations\"]\n",
    "        # encoded_csfs = self.csf_encoder(\n",
    "        #     csfs, input_dict[\"n_electrons\"], input_dict[\"n_protons\"]\n",
    "        # )\n",
    "        # output = self.transformer_encoder(\n",
    "        #     encoded_csfs, src_key_padding_mask=input_dict[\"pad_mask\"]\n",
    "        # )  # src_key_padding_mask = ~input_dict['mask']\n",
    "        # # output = output[:, 0, :]\n",
    "        # output = self.decoder(output)\n",
    "        # return F.sigmoid(output).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/models/components/loss_function_wrappers.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LossFuncMaskWrapper(nn.Module):\n",
    "    def __init__(self, loss_fn: nn.Module):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loss_fn (nn.Module): A PyTorch loss function like CrossEntropyLoss, MSELoss, etc.\n",
    "        \"\"\"\n",
    "        super(LossFuncMaskWrapper, self).__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, input, target, mask= None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Tensor): Predicted values of size (N, *) where * means any number of additional dimensions.\n",
    "            mask (Tensor): Mask of size (N) to filter out the padded values.\n",
    "            target (Tensor): True values of size (N, *).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Computed loss after applying the mask.\n",
    "        \"\"\"\n",
    "        # Apply the mask to input and target\n",
    "        if mask is None:\n",
    "            return self.loss_fn(input, target)\n",
    "        else:\n",
    "            return self.loss_fn(input[mask], target[mask])\n",
    "        \n",
    "        # masked_input = input[mask].float()\n",
    "        # masked_target = target[mask].float()\n",
    "\n",
    "        # # Compute the loss using the provided loss function\n",
    "        # loss = self.loss_fn(masked_input, masked_target)\n",
    "        \n",
    "        # return loss\n",
    "\n",
    "\n",
    "class GaussianNLLLossWrapper(nn.Module):\n",
    "    def __init__(self, loss_fn: nn.Module):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            loss_fn (nn.Module): A PyTorch loss function like GaussianNLLLoss which takes two inputs and returns the loss.\n",
    "        \"\"\"\n",
    "        super(GaussianNLLLossWrapper, self).__init__()\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, input, target,  mask = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (Tensor): Predicted means of size (N, 2) first column is the mean and the second column is the variance.\n",
    "            mask (Tensor): Mask of size (N) to filter out the padded values.\n",
    "            target (Tensor): True values of size (N)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Computed Gaussian negative log likelihood loss.\n",
    "        \"\"\"\n",
    "        # Ensure variances are non-negative by adding eps (if not handled elsewhere)\n",
    "        mean = input[:,:,0]#[mask]\n",
    "        var = input[:,:,1]#[mask]#.clamp(min=self.eps)\n",
    "        target = target.float() #[mask]\n",
    "        \n",
    "        # Compute the loss using GaussianNLLLoss\n",
    "        loss = self.loss_fn(mean, target, var)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "class DiscretizedNLLLoss(nn.Module):\n",
    "    def __init__(self, loss_fn: nn.Module, num_bins: int, min_value: float, max_value: float):\n",
    "        \"\"\"\n",
    "        :param num_bins: Number of bins to discretize the continuous range\n",
    "        :param min_value: Minimum value of the range to discretize\n",
    "        :param max_value: Maximum value of the range to discretize\n",
    "        \"\"\"\n",
    "        super(DiscretizedNLLLoss, self).__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.num_bins = num_bins\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        \n",
    "        # Calculate the width of each bin\n",
    "        self.bin_width = (max_value - min_value) / num_bins\n",
    "        \n",
    "        # Bins are represented by their center values\n",
    "        self.bin_centers = torch.linspace(min_value + self.bin_width / 2,\n",
    "                                          max_value - self.bin_width / 2, num_bins)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        :param predictions: The continuous predictions from the model [batch_size, 1]\n",
    "        :param targets: The continuous target values [batch_size, 1]\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert continuous target values into bin indices\n",
    "        target_bin_indices = ((targets - self.min_value) / self.bin_width).long().clamp(0, self.num_bins - 1)\n",
    "        \n",
    "        # Apply CrossEntropyLoss (which includes log-softmax)\n",
    "        loss = self.loss_fn(logits, target_bin_indices.squeeze(-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.components.CSF_encoders import simple_CSF_encoder\n",
    "from src.models.components.Transformer_encoder_model import simple_transformer_encoder_model\n",
    "from src.models.components.loss_function_wrappers import LossFuncMaskWrapper\n",
    "# from src.data.components.datasets import GroupedDictDataset\n",
    "from src.data.components.samplers import GroupedBatchSampler\n",
    "\n",
    "import pickle\n",
    "with open(cfg_train.data.data_dir, 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "batch_size = 8 #cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = 8\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model,output_activation=torch.nn.Sigmoid())\n",
    "\n",
    "loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum'))  #CrossEntropyLoss\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    preds= model(batch)\n",
    "    targets = batch['converged']\n",
    "    # print()\n",
    "\n",
    "    # print(preds.shape)\n",
    "    # print(batch['converged'].shape)\n",
    "\n",
    "    mask_converged = batch['converged_mask']\n",
    "    # mask_effect = batch['effect_mask']\n",
    "    print('filling numbers')\n",
    "    print(batch['filling_numbers'])\n",
    "    print('targets')\n",
    "    print(batch['converged'])\n",
    "    print(batch['effect'])\n",
    "    print('masks')\n",
    "    print(mask_converged)\n",
    "    # print(mask_effect)\n",
    "    print('masked targets')\n",
    "    print(batch['converged'][mask_converged])\n",
    "    # print(batch['effect'][mask_effect])\n",
    "    \n",
    "    loss = loss_fn(preds, targets, mask_converged)\n",
    "    print('loss')\n",
    "    print(loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.components.CSF_encoders import simple_CSF_encoder\n",
    "# from src.models.components.Transformer_encoder_model import simple_transformer_encoder_model\n",
    "from src.models.components.loss_function_wrappers import LossFuncMaskWrapper\n",
    "# from src.data.components.datasets import GroupedDictDataset\n",
    "from src.data.components.samplers import GroupedBatchSampler\n",
    "\n",
    "import pickle\n",
    "with open(cfg_train.data.data_dir, 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "batch_size = 8 #cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = 8\n",
    "csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model,output_activation=torch.nn.Sigmoid())\n",
    "\n",
    "loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum'))  #CrossEntropyLoss\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    preds= model(batch)\n",
    "    targets = batch['converged']\n",
    "    # print()\n",
    "\n",
    "    # print(preds.shape)\n",
    "    # print(batch['converged'].shape)\n",
    "\n",
    "    mask_converged = batch['converged_mask']\n",
    "    # mask_effect = batch['effect_mask']\n",
    "    print('filling numbers')\n",
    "    print(batch['filling_numbers'])\n",
    "    print('targets')\n",
    "    print(batch['converged'])\n",
    "    print(batch['effect'])\n",
    "    print('masks')\n",
    "    print(mask_converged)\n",
    "    # print(mask_effect)\n",
    "    print('masked targets')\n",
    "    print(batch['converged'][mask_converged])\n",
    "    # print(batch['effect'][mask_effect])\n",
    "    \n",
    "    loss = loss_fn(preds, targets, mask_converged)\n",
    "    print('loss')\n",
    "    print(loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotary embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.models.components.CSF_encoders import simple_CSF_encoder\n",
    "from src.models.components.Transformer_encoder_model import simple_transformer_encoder_model\n",
    "from src.models.components.loss_function_wrappers import LossFuncMaskWrapper\n",
    "# from src.data.components.datasets import GroupedDictDataset\n",
    "from src.data.components.samplers import GroupedBatchSampler\n",
    "\n",
    "import pickle\n",
    "with open(cfg_train.data.data_dir, 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "\n",
    "batch_size = 8 #cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = 8\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model,output_activation=torch.nn.Sigmoid())\n",
    "\n",
    "loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum'))  #CrossEntropyLoss\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    preds= model(batch)\n",
    "    targets = batch['converged']\n",
    "    # print()\n",
    "\n",
    "    # print(preds.shape)\n",
    "    # print(batch['converged'].shape)\n",
    "\n",
    "    mask_converged = batch['converged_mask']\n",
    "    # mask_effect = batch['effect_mask']\n",
    "    print('filling numbers')\n",
    "    print(batch['filling_numbers'])\n",
    "    print('targets')\n",
    "    print(batch['converged'])\n",
    "    print(batch['effect'])\n",
    "    print('masks')\n",
    "    print(mask_converged)\n",
    "    # print(mask_effect)\n",
    "    print('masked targets')\n",
    "    print(batch['converged'][mask_converged])\n",
    "    print(batch['effect'])\n",
    "    \n",
    "    loss = loss_fn(preds, targets, mask_converged)\n",
    "    print('loss')\n",
    "    print(loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RotaryEmbedding2Angle4D(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        \"\"\"\n",
    "        Initialize the RepeatedRotaryEmbedding module.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Dimension of the embeddings, must be divisible by 4.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim % 4 == 0, \"Embedding dimension must be divisible by 4\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, embeddings, theta, phi):\n",
    "        \"\"\"\n",
    "        Applies the repeated rotation on the embeddings using angles theta and phi.\n",
    "\n",
    "        Args:\n",
    "            embeddings (torch.Tensor): Input embeddings of shape [batch_size, n, dim].\n",
    "            theta (torch.Tensor): Rotation angles for xy planes of shape [batch_size].\n",
    "            phi (torch.Tensor): Rotation angles for zw planes of shape [batch_size].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Rotated embeddings of the same shape as input.\n",
    "        \"\"\"\n",
    "        batch_size, n, dim = embeddings.shape\n",
    "        assert dim == self.dim, f\"Input embedding dimension {dim} does not match initialized dimension {self.dim}\"\n",
    "\n",
    "        num_blocks = dim // 4  # Number of 4x4 blocks per embedding\n",
    "\n",
    "        # Compute rotation components\n",
    "        cos_theta = torch.cos(theta).unsqueeze(1).repeat(1, num_blocks)  # Shape: [batch_size, num_blocks]\n",
    "        sin_theta = torch.sin(theta).unsqueeze(1).repeat(1, num_blocks)  # Shape: [batch_size, num_blocks]\n",
    "        cos_phi = torch.cos(phi).unsqueeze(1).repeat(1, num_blocks)      # Shape: [batch_size, num_blocks]\n",
    "        sin_phi = torch.sin(phi).unsqueeze(1).repeat(1, num_blocks)      # Shape: [batch_size, num_blocks]\n",
    "\n",
    "        # Create block-diagonal rotation matrix for the entire batch\n",
    "        R = torch.zeros(batch_size, dim, dim, device=embeddings.device)\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            # Define indices for the i-th block\n",
    "            start = i * 4\n",
    "            end = start + 4\n",
    "\n",
    "            # Fill the block-diagonal matrix for all batches\n",
    "            R[:, start:start+2, start:start+2] = torch.stack([\n",
    "                torch.stack([cos_theta[:, i], -sin_theta[:, i]], dim=-1),\n",
    "                torch.stack([sin_theta[:, i], cos_theta[:, i]], dim=-1)\n",
    "            ], dim=1)\n",
    "\n",
    "            R[:, start+2:end, start+2:end] = torch.stack([\n",
    "                torch.stack([cos_phi[:, i], -sin_phi[:, i]], dim=-1),\n",
    "                torch.stack([sin_phi[:, i], cos_phi[:, i]], dim=-1)\n",
    "            ], dim=1)\n",
    "\n",
    "        # Apply the rotation to embeddings\n",
    "        rotated_embeddings = torch.einsum('bnd,bdm->bnm', embeddings, R)\n",
    "\n",
    "        return rotated_embeddings\n",
    "\n",
    "\n",
    "\n",
    "class PairEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, pair_list=[(0, 0), (1, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (0, 3), (2, 2), (1, 3), (0, 4), (0, 5), (3, 2), (1, 4), (2, 3), (3, 3), (2, 4), (1, 5), (3, 4), (4, 3), (2, 5), (3, 5), (4, 4), (5, 4), (4, 5), (5, 5)]):\n",
    "        super(PairEmbedding, self).__init__()\n",
    "        \n",
    "        # Initialize the embedding layer\n",
    "        self.embedding = nn.Embedding(len(pair_list), embedding_dim)\n",
    "        \n",
    "        # Create a lookup table\n",
    "        self.max_val = max(max(pair) for pair in pair_list)  # Find the maximum integer in the pairs\n",
    "        self.lookup_table = torch.full((self.max_val + 1, self.max_val + 1), -1, dtype=torch.long)\n",
    "        \n",
    "        # Fill the lookup table with indices\n",
    "        for idx, pair in enumerate(pair_list):\n",
    "            self.lookup_table[pair[0], pair[1]] = idx\n",
    "\n",
    "    def forward(self, pair_tensor):\n",
    "        # pair_tensor is of shape [batch_size, n, 2]\n",
    "        \n",
    "        # Use the lookup table to find indices for all pairs in the batch\n",
    "        indices = self.lookup_table[pair_tensor[..., 0], pair_tensor[..., 1]]\n",
    "        # indices will have shape [batch_size, n]\n",
    "        # print(indices)\n",
    "        \n",
    "        # Pass the indices to the embedding layer\n",
    "        embedded = self.embedding(indices)  # This will be of shape [batch_size, n, embedding_dim]\n",
    "        return embedded\n",
    "\n",
    "# # Define the pairs and instantiate the module\n",
    "# pairs = [\n",
    "#     (0, 0), (1, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 1),\n",
    "#     (0, 3), (2, 2), (1, 3), (0, 4), (0, 5), (3, 2), (1, 4),\n",
    "#     (2, 3), (3, 3), (2, 4), (1, 5), (3, 4), (4, 3), (2, 5),\n",
    "#     (3, 5), (4, 4), (5, 4), (4, 5), (5, 5)\n",
    "# ]\n",
    "# embedding_dim = 8  # Example embedding dimension\n",
    "# pair_embedding = PairEmbedding(embedding_dim, pairs)\n",
    "# rotate = RotaryEmbedding2Angle4D(embedding_dim)\n",
    "\n",
    "# # Example usage with a batch of pairs\n",
    "# batch_pair_tensor = torch.tensor([[[1, 3], [0, 1], [0, 1], [5,5]], [[3, 4], [2, 5], [0, 1],[5,5]], [[3, 4], [2, 5], [0, 1],[5,5]]])  # Shape [2, 3, 2]\n",
    "# print(batch_pair_tensor.shape)\n",
    "# embedded = pair_embedding(batch_pair_tensor)\n",
    "# print(embedded)  # Should output embeddings with shape [batch_size, n, embedding_dim]\n",
    "# rotated = rotate(embedded, torch.tensor(np.pi), torch.tensor(np.pi))\n",
    "# print(rotated)  # Should output embeddings with shape [batch_size, n, embedding_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8  # Example embedding dimension\n",
    "pairs = [\n",
    "    (0, 0), (1, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 1),\n",
    "    (0, 3), (2, 2), (1, 3), (0, 4), (0, 5), (3, 2), (1, 4),\n",
    "    (2, 3), (3, 3), (2, 4), (1, 5), (3, 4), (4, 3), (2, 5),\n",
    "    (3, 5), (4, 4), (5, 4), (4, 5), (5, 5)\n",
    "]\n",
    "\n",
    "pair_embedding = PairEmbedding(embedding_dim, pairs)\n",
    "rotate = RotaryEmbedding2Angle4D(embedding_dim)\n",
    "\n",
    "# Example batch of embeddings and angles\n",
    "batch_pair_tensor = torch.tensor([\n",
    "    [[1, 3], [0, 1], [0, 1], [5, 5]],\n",
    "    [[3, 4], [2, 5], [0, 1], [5, 5]],\n",
    "    [[3, 4], [2, 5], [0, 1], [5, 5]]\n",
    "])  # Shape [batch_size, n, 2]\n",
    "embedded = pair_embedding(batch_pair_tensor)\n",
    "\n",
    "# Angles for each batch element\n",
    "theta = torch.tensor([np.pi*2, np.pi*2, np.pi*2])  # Shape [batch_size]\n",
    "phi = torch.tensor([np.pi*2, np.pi*2, np.pi*2])    # Shape [batch_size]\n",
    "\n",
    "rotated = rotate(embedded, theta, phi)\n",
    "print(rotated.shape)  # Should output embeddings with shape [batch_size, n, embedding_dim]\n",
    "\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_2pi = torch.full((batch_size,), 2 * torch.pi)\n",
    "phi_2pi = torch.full((batch_size,), 2 * torch.pi)\n",
    "theta_pi = torch.full((batch_size,), torch.pi)\n",
    "phi_pi = torch.full((batch_size,), torch.pi)\n",
    "\n",
    "rotated_2pi = rotate(embeddings, theta_2pi, phi_2pi)\n",
    "rotated_pi = rotate(embeddings, theta_pi, phi_pi)\n",
    "\n",
    "identity_test = torch.allclose(embeddings, rotated_2pi, atol=1e-5)\n",
    "negation_test = torch.allclose(embeddings * -1, rotated_pi, atol=1e-5)\n",
    "\n",
    "print(\"Identity Test (2π):\", identity_test)\n",
    "print(\"Negation Test (π):\", negation_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified test case\n",
    "embedding_dim = 8  # Must be divisible by 4\n",
    "batch_size, n = 2, 4  # Example batch size and sequence length\n",
    "\n",
    "# Example embeddings\n",
    "embeddings = torch.randn(batch_size, n, embedding_dim)\n",
    "\n",
    "# Angles for testing\n",
    "theta_2pi = torch.full((batch_size,), 2 * torch.pi)\n",
    "phi_2pi = torch.full((batch_size,), 2 * torch.pi)\n",
    "theta_pi = torch.full((batch_size,), torch.pi)\n",
    "phi_pi = torch.full((batch_size,), torch.pi)\n",
    "\n",
    "# Initialize the rotary embedding layer\n",
    "rotate = RotaryEmbedding2Angle4D(embedding_dim)\n",
    "\n",
    "# Test rotations\n",
    "rotated_2pi = rotate(embeddings, theta_2pi, phi_2pi)  # Rotate with 2*pi\n",
    "rotated_pi = rotate(embeddings, theta_pi, phi_pi)     # Rotate with pi\n",
    "\n",
    "# Compare results\n",
    "identity_test = torch.allclose(embeddings, rotated_2pi, atol=1e-5)  # Check if rotation by 2*pi is identity\n",
    "negation_test = torch.allclose(embeddings * -1, rotated_pi, atol=1e-5)  # Check if rotation by pi negates\n",
    "\n",
    "identity_test, negation_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 #cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = 8\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "# csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "model = simple_transformer_encoder_model(\n",
    "    csf_encoder, \n",
    "    d_model=d_model,\n",
    "    output_activation=torch.nn.ReLU(),\n",
    "    output_size=2\n",
    "    )\n",
    "\n",
    "loss_fn=GaussianNLLLossWrapper(nn.GaussianNLLLoss(reduction='sum'))\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    preds= model(batch)\n",
    "    # print(preds.shape)\n",
    "    target = batch['converged']\n",
    "    # print()\n",
    "\n",
    "    # print(preds.shape)\n",
    "    # print(batch['converged'].shape)\n",
    "\n",
    "    mask_converged = batch['converged_mask']\n",
    "    # mask_effect = batch['effect_mask']\n",
    "    print('targets')\n",
    "    print(batch['converged'].shape)\n",
    "    print(batch['effect'].shape)\n",
    "    print('preds')\n",
    "    print(preds.shape)\n",
    "    print('masks')\n",
    "    print(mask_converged.shape)\n",
    "    # print(mask_effect.shape)\n",
    "    # print('masked targets')\n",
    "    # print(batch['converged'][mask_converged])\n",
    "    # print(batch['effect'][mask_effect])\n",
    "    loss = loss_fn(preds, target, mask_converged)\n",
    "    print('loss')\n",
    "    print(loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # i+=1\n",
    "    # if i == 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model and data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'is mps available ? {torch.backends.mps.is_available()}')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 8 #cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = 8\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "# csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model,output_activation=F.sigmoid)\n",
    "\n",
    "\n",
    "loss_fn=LossFuncMaskWrapper(torch.nn.CrossEntropyLoss(reduction='sum')).to(device)\n",
    "model.to(device)\n",
    "\n",
    "i = 0\n",
    "for batch in dataloader:\n",
    "    batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    preds= model(batch)\n",
    "    targets = batch['converged']\n",
    "    # print()\n",
    "\n",
    "    mask_converged = batch['converged_mask']\n",
    "    # mask_effect = batch['effect_mask']\n",
    "    print('targets')\n",
    "    print(batch['converged'])\n",
    "    print(batch['effect'])\n",
    "    print('masks')\n",
    "    print(mask_converged)\n",
    "    # print(mask_effect)\n",
    "    print('masked targets')\n",
    "    print(batch['converged'][mask_converged])\n",
    "    # print(batch['effect'][mask_effect])\n",
    "    loss = loss_fn(preds, targets, mask_converged)\n",
    "    print('loss')\n",
    "    print(loss)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    i+=1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pure pytorch train model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCE converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "print(f'is mps available? {torch.backends.mps.is_available()}')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch_size = cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = cfg_train.model.model.d_model\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "# csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "# model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.sigmoid,output_size=1)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.relu,output_size=2)\n",
    "\n",
    "# loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum')).to(device)  #CrossEntropyLoss\n",
    "loss_fn=GaussianNLLLossWrapper(nn.GaussianNLLLoss(reduction='sum'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)  # Initialize the optimizer\n",
    "\n",
    "num_epochs = 10  # Number of epochs to train for\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Assuming your DataLoader outputs a batch as a dictionary with 'CSFs', 'n_electrons', 'n_protons', and 'effect'\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(batch)\n",
    "        print(preds.shape)\n",
    "        # targets = batch['converged']\n",
    "        targets = batch['effect']\n",
    "        # print(targets.shape)\n",
    "\n",
    "        mask_converged = batch['converged_mask']\n",
    "        # mask_effect = batch['effect_mask']\n",
    "        # print(mask_effect.shape)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, targets )#mask_converged\n",
    "        # loss = loss_fn(preds, targets, mask_converged )#mask_converged\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * preds.size(0)  # Multiply by batch size for total loss\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)  # Average loss per sample\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "print(f'is mps available? {torch.backends.mps.is_available()}')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch_size = cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = cfg_train.model.model.d_model\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "# csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "# model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.sigmoid,output_size=1)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.relu,output_size=2)\n",
    "\n",
    "# loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum')).to(device)  #CrossEntropyLoss\n",
    "loss_fn=GaussianNLLLossWrapper(nn.GaussianNLLLoss(reduction='sum'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)  # Initialize the optimizer\n",
    "\n",
    "num_epochs = 10  # Number of epochs to train for\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Assuming your DataLoader outputs a batch as a dictionary with 'CSFs', 'n_electrons', 'n_protons', and 'effect'\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(batch)\n",
    "        # targets = batch['converged']\n",
    "        targets = batch['effect']\n",
    "        # print(targets.shape)\n",
    "\n",
    "        mask_converged = batch['converged_mask']\n",
    "        # mask_effect = batch['effect_mask']\n",
    "        # print(mask_effect.shape)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, targets )#mask_converged\n",
    "        # loss = loss_fn(preds, targets, mask_converged )#mask_converged\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * preds.size(0)  # Multiply by batch size for total loss\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)  # Average loss per sample\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NLL effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "print(f'is mps available? {torch.backends.mps.is_available()}')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "batch_size = cfg_train.data.batch_size\n",
    "\n",
    "dataset = GroupedDictDataset( data_dict, remove_nan_effect=True)\n",
    "sampler = GroupedBatchSampler(dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "d_model = cfg_train.model.model.d_model\n",
    "csf_encoder= simple_CSF_encoder(d_model)\n",
    "# csf_encoder= ExcitaionEmbeddingIonRoPE(d_model)\n",
    "# model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.sigmoid,output_size=1)\n",
    "model = simple_transformer_encoder_model(csf_encoder, d_model=d_model, output_activation=F.relu,output_size=2)\n",
    "\n",
    "# loss_fn=LossFuncMaskWrapper(torch.nn.BCELoss(reduction='sum')).to(device)  #CrossEntropyLoss\n",
    "loss_fn=GaussianNLLLossWrapper(nn.GaussianNLLLoss(reduction='sum'))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)  # Initialize the optimizer\n",
    "\n",
    "num_epochs = 10  # Number of epochs to train for\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Assuming your DataLoader outputs a batch as a dictionary with 'CSFs', 'n_electrons', 'n_protons', and 'effect'\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(batch)\n",
    "        print(preds.shape)\n",
    "        # targets = batch['converged']\n",
    "        targets = batch['effect']\n",
    "        # print(targets.shape)\n",
    "\n",
    "        mask_converged = batch['converged_mask']\n",
    "        # mask_effect = batch['effect_mask']\n",
    "        # print(mask_effect.shape)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(preds, targets )#mask_converged\n",
    "        # loss = loss_fn(preds, targets, mask_converged )#mask_converged\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * preds.size(0)  # Multiply by batch size for total loss\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)  # Average loss per sample\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch lightning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/data/dict_datamodule.py\n",
    "from typing import Any, Dict, Optional, Tuple, Callable\n",
    "\n",
    "import torch\n",
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import pickle\n",
    "\n",
    "from src.data.components.datasets import GroupedDictDataset\n",
    "from src.data.components.samplers import GroupedBatchSampler\n",
    "from src.data.components.collate_fns import dict_collate_fn\n",
    "from src.data.components.data_utils import load_data_dict\n",
    "\n",
    "class DictDataModule(LightningDataModule):\n",
    "    \"\"\"`LightningDataModule` for the MNIST dataset.\n",
    "\n",
    "    write about structure of the data, download, split, transform, etc...\n",
    "\n",
    "    A `LightningDataModule` implements 7 key methods:\n",
    "\n",
    "    ```python\n",
    "        def prepare_data(self):\n",
    "        # Things to do on 1 GPU/TPU (not on every GPU/TPU in DDP).\n",
    "        # Download data, pre-process, split, save to disk, etc...\n",
    "\n",
    "        def setup(self, stage):\n",
    "        # Things to do on every process in DDP.\n",
    "        # Load data, set variables, etc...\n",
    "\n",
    "        def train_dataloader(self):\n",
    "        # return train dataloader\n",
    "\n",
    "        def val_dataloader(self):\n",
    "        # return validation dataloader\n",
    "\n",
    "        def test_dataloader(self):\n",
    "        # return test dataloader\n",
    "\n",
    "        def predict_dataloader(self):\n",
    "        # return predict dataloader\n",
    "\n",
    "        def teardown(self, stage):\n",
    "        # Called on every process in DDP.\n",
    "        # Clean up after fit or test.\n",
    "    ```\n",
    "\n",
    "    This allows you to share a full dataset without explaining how to download,\n",
    "    split, transform and process the data.\n",
    "\n",
    "    Read the docs:\n",
    "        https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data/\",\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        train_val_splitter: Optional[Callable] = None,\n",
    "        shuffle: bool = True,\n",
    "        pin_memory: bool = False,\n",
    "        remove_nan_effect: bool = False,\n",
    "        ion_include = None,\n",
    "        persistent_workers: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a `HDF5DataModule`.\n",
    "\n",
    "        :param data_dir: The data directory. Defaults to `\"data/\"`.\n",
    "        :param train_val_test_split: The train, validation and test split. Defaults to `(55_000, 5_000, 10_000)`.\n",
    "        :param batch_size: The batch size. Defaults to `64`.\n",
    "        :param num_workers: The number of workers. Defaults to `0`.\n",
    "        :param pin_memory: Whether to pin memory. Defaults to `False`.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_dict = None\n",
    "\n",
    "        self.train_val_splitter = self.hparams.train_val_splitter\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "        self.data_unseen: Optional[Dataset] = None\n",
    "        self.data_large: Optional[Dataset] = None\n",
    "\n",
    "        self.batch_size_per_device = batch_size\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"Download data if needed. Lightning ensures that `self.prepare_data()` is called only\n",
    "        within a single process on CPU, so you can safely add your downloading logic within. In\n",
    "        case of multi-node training, the execution of this hook depends upon\n",
    "        `self.prepare_data_per_node()`.\n",
    "\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        # Load the data dictionary from the data directory\n",
    "        self.data_dict = load_data_dict( self.hparams.data_dir)\n",
    "        self.data_dict_train, self.data_dict_val, self.data_dict_unseen, self.data_dict_large = self.train_val_splitter( self.data_dict)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n",
    "\n",
    "        This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and\n",
    "        `trainer.predict()`, so be careful not to execute things like random split twice! Also, it is called after\n",
    "        `self.prepare_data()` and there is a barrier in between which ensures that all the processes proceed to\n",
    "        `self.setup()` once the data is prepared and available for use.\n",
    "\n",
    "        :param stage: The stage to setup. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`. Defaults to ``None``.\n",
    "        \"\"\"\n",
    "        # Divide batch size by the number of devices.\n",
    "        if self.trainer is not None:\n",
    "            if self.hparams.batch_size % self.trainer.world_size != 0:\n",
    "                raise RuntimeError(\n",
    "                    f\"Batch size ({self.hparams.batch_size}) is not divisible by the number of devices ({self.trainer.world_size}).\"\n",
    "                )\n",
    "            self.batch_size_per_device = (\n",
    "                self.hparams.batch_size // self.trainer.world_size\n",
    "            )\n",
    "\n",
    "        \n",
    "        # ion_include = [tuple(item) for item in self.hparams.ion_include] if self.hparams.ion_include else None\n",
    "        \n",
    "        # load and split datasets only if not loaded already\n",
    "        if not self.data_train:\n",
    "            self.data_train = GroupedDictDataset(\n",
    "                data_dict=self.data_dict_train, \n",
    "                remove_nan_effect=self.hparams.remove_nan_effect,\n",
    "                # ion_include=ion_include,\n",
    "                )\n",
    "        if not self.data_val:\n",
    "            self.data_val = GroupedDictDataset(\n",
    "                data_dict=self.data_dict_val, \n",
    "                remove_nan_effect=self.hparams.remove_nan_effect,\n",
    "                # ion_include=ion_include,\n",
    "                )\n",
    "        if not self.data_test:\n",
    "            self.data_test = GroupedDictDataset(\n",
    "                data_dict=self.data_dict, \n",
    "                remove_nan_effect=self.hparams.remove_nan_effect,\n",
    "                # ion_include=ion_include,\n",
    "                )\n",
    "        if not self.data_unseen:\n",
    "            self.data_unseen = GroupedDictDataset(\n",
    "                data_dict=self.data_dict_unseen, \n",
    "                remove_nan_effect=self.hparams.remove_nan_effect,\n",
    "                # ion_include=ion_include,\n",
    "                )\n",
    "        if not self.data_large:\n",
    "            self.data_large = GroupedDictDataset(\n",
    "                data_dict=self.data_dict_large, \n",
    "                remove_nan_effect=self.hparams.remove_nan_effect,\n",
    "                # ion_include=ion_include,\n",
    "                )\n",
    "\n",
    "        print(len(self.data_train),len(self.data_val),len(self.data_test),len(self.data_unseen),len(self.data_large))\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the train dataloader.\n",
    "\n",
    "        :return: The train dataloader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_sampler=GroupedBatchSampler(self.data_train, batch_size =self.batch_size_per_device, shuffle=self.hparams.shuffle),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            persistent_workers=self.hparams.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the validation dataloader.\n",
    "\n",
    "        :return: The validation dataloader.\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_sampler=GroupedBatchSampler(self.data_val, batch_size =self.batch_size_per_device, shuffle=self.hparams.shuffle),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            persistent_workers=self.hparams.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"Create and return the test dataloader.\n",
    "\n",
    "        :return: The test dataloader.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_sampler=GroupedBatchSampler(self.data_val, batch_size =self.batch_size_per_device, shuffle=self.hparams.shuffle), #data_test,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            persistent_workers=self.hparams.persistent_workers,\n",
    "            ),\n",
    "            DataLoader(\n",
    "            dataset=self.data_unseen,\n",
    "            batch_sampler=GroupedBatchSampler(self.data_unseen, batch_size =self.batch_size_per_device, shuffle=self.hparams.shuffle),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            persistent_workers=self.hparams.persistent_workers,\n",
    "            ),\n",
    "            DataLoader(\n",
    "            dataset=self.data_large,\n",
    "            batch_sampler=GroupedBatchSampler(self.data_large, batch_size = 4, shuffle=self.hparams.shuffle), #self.batch_size_per_device\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            persistent_workers=self.hparams.persistent_workers,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def teardown(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"Lightning hook for cleaning up after `trainer.fit()`, `trainer.validate()`,\n",
    "        `trainer.test()`, and `trainer.predict()`.\n",
    "\n",
    "        :param stage: The stage being torn down. Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n",
    "            Defaults to ``None``.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def state_dict(self) -> Dict[Any, Any]:\n",
    "        \"\"\"Called when saving a checkpoint. Implement to generate and save the datamodule state.\n",
    "\n",
    "        :return: A dictionary containing the datamodule state that you want to save.\n",
    "        \"\"\"\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n",
    "        \"\"\"Called when loading a checkpoint. Implement to reload datamodule state given datamodule\n",
    "        `state_dict()`.\n",
    "\n",
    "        :param state_dict: The datamodule state returned by `self.state_dict()`.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _ = DictDataModule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load /Users/moustholmes/Projects/METAL-AI/configs/data/dict_dataset.yaml\n",
    "_target_: src.data.dict_datamodule.DictDataModule\n",
    "data_dir: ${paths.data_dir}\n",
    "batch_size: 128 # Needs to be divisible by the number of devices (e.g., if in a distributed setup)\n",
    "train_val_splitter:\n",
    "    _target_: src.data.components.data_utils.TopASFSizeTrainValSplitter\n",
    "    validation_percentage : 0.15\n",
    "num_workers: 0\n",
    "shuffle: False\n",
    "remove_nan_effect: False\n",
    "pin_memory: True\n",
    "persistent_workers: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "cfg_train = compose(config_name='train')\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "print(datamodule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /Users/moustholmes/Projects/METAL-AI/src/models/metalAI_module.py\n",
    "from typing import Any, Dict, Tuple\n",
    "import pickle\n",
    "import copy\n",
    "import torch\n",
    "from lightning import LightningModule\n",
    "from torchmetrics import MaxMetric, MeanMetric, MinMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy\n",
    "\n",
    "\n",
    "class MetalAILitModule(LightningModule):\n",
    "    \"\"\"Example of a `LightningModule` for MNIST classification.\n",
    "\n",
    "    A `LightningModule` implements 8 key methods:\n",
    "\n",
    "    ```python\n",
    "    def __init__(self):\n",
    "    # Define initialization code here.\n",
    "\n",
    "    def setup(self, stage):\n",
    "    # Things to setup before each stage, 'fit', 'validate', 'test', 'predict'.\n",
    "    # This hook is called on every process when using DDP.\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # The complete training step.\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "    # The complete validation step.\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "    # The complete test step.\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "    # The complete predict step.\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "    # Define and configure optimizers and LR schedulers.\n",
    "    ```\n",
    "\n",
    "    Docs:\n",
    "        https://lightning.ai/docs/pytorch/latest/common/lightning_module.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        target_name: str,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduler: torch.optim.lr_scheduler,\n",
    "        compile: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a `MNISTLitModule`.\n",
    "\n",
    "        :param net: The model to train.\n",
    "        :param optimizer: The optimizer to use for training.\n",
    "        :param scheduler: The learning rate scheduler to use for training.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        # target name for specifying convergence or effect prediction\n",
    "        self.target_name = target_name\n",
    "\n",
    "        # loss function\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        # for averaging loss across batches\n",
    "        self.train_loss = MeanMetric()\n",
    "        self.val_loss = MeanMetric()\n",
    "\n",
    "        #\n",
    "        self.test_val_loss = MeanMetric()\n",
    "        self.test_unseen_loss = MeanMetric()\n",
    "        self.test_large_loss = MeanMetric()\n",
    "\n",
    "        self.val_loss_best = MinMetric()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Perform a forward pass through the model `self.net`.\n",
    "\n",
    "        :param x: A tensor of images.\n",
    "        :return: A tensor of logits.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_train_start(self) -> None:\n",
    "        \"\"\"Lightning hook that is called when training begins.\"\"\"\n",
    "        # by default lightning executes validation step sanity checks before training starts,\n",
    "        # so it's worth to make sure validation metrics don't store results from these checks\n",
    "        self.val_loss.reset()\n",
    "        self.val_loss_best.reset()\n",
    "\n",
    "    def model_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Perform a single model step on a batch of data.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target labels.\n",
    "\n",
    "        :return: A tuple containing (in order):\n",
    "            - A tensor of losses.\n",
    "            - A tensor of predictions.\n",
    "            - A tensor of target labels.\n",
    "        \"\"\"\n",
    "\n",
    "        preds = self.forward(batch)\n",
    "        targets = batch[self.target_name]\n",
    "        \n",
    "        if self.target_name == 'converged':\n",
    "            mask = batch[self.target_name + \"_mask\"]\n",
    "            loss = self.loss_fn(preds, targets, mask)\n",
    "        else:\n",
    "            loss = self.loss_fn(preds, targets)\n",
    "            mask = None\n",
    "        return loss, preds, targets, mask # preds[mask], targets[mask],\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Perform a single training step on a batch of data from the training set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        :return: A tensor of losses between model predictions and targets.\n",
    "        \"\"\"\n",
    "        loss, preds, targets, mask = self.model_step(batch)\n",
    "\n",
    "        # update and log loss\n",
    "        self.train_loss(loss)\n",
    "        self.log(\n",
    "            \"train/loss\", self.train_loss, on_step=False, on_epoch=True, prog_bar=True\n",
    "        )\n",
    "        # return loss or backpropagation will fail\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets, 'mask': mask}\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        \"Lightning hook that is called when a training epoch ends.\"\n",
    "        pass\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int, dataloader_idx: int = 0\n",
    "    ) -> None:\n",
    "        \"\"\"Perform a single validation step on a batch of data from the validation set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, preds, targets, mask = self.model_step(batch)\n",
    "\n",
    "        # update and log loss\n",
    "        self.val_loss(loss)\n",
    "        self.val_loss_best(loss)\n",
    "\n",
    "        self.log(\"val/loss\", self.val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets, 'mask': mask}\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        \"Lightning hook that is called when a validation epoch ends.\"\n",
    "        # acc = self.val_acc.compute()  # get current val acc\n",
    "        # self.val_acc_best(acc)  # update best so far val acc\n",
    "        # log `val_acc_best` as a value through `.compute()` method, instead of as a metric object\n",
    "        # otherwise metric would be reset by lightning after each epoch\n",
    "        self.log(\"val/loss_best\", self.val_loss_best.compute(), sync_dist=True, prog_bar=True)\n",
    "        # pass\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int, dataloader_idx: int = 0\n",
    "    ) -> None:\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        loss, preds, targets, mask = self.model_step(batch)\n",
    "\n",
    "        # update and log loss\n",
    "        if dataloader_idx == 0:\n",
    "            self.test_val_loss(loss)\n",
    "\n",
    "            self.log(\"test/val_loss\", self.test_val_loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "        elif dataloader_idx == 1:\n",
    "            self.test_unseen_loss(loss)\n",
    "\n",
    "            self.log(\"test/unseen_loss\", self.test_unseen_loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "        elif dataloader_idx == 2:\n",
    "            self.test_large_loss(loss)\n",
    "\n",
    "            self.log(\"test/large_loss\", self.test_large_loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "   \n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets, 'mask': mask}\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        \"\"\"Lightning hook that is called at the beginning of fit (train + validate), validate,\n",
    "        test, or predict.\n",
    "\n",
    "        This is a good hook when you need to build models dynamically or adjust something about\n",
    "        them. This hook is called on every process when using DDP.\n",
    "\n",
    "        :param stage: Either `\"fit\"`, `\"validate\"`, `\"test\"`, or `\"predict\"`.\n",
    "        \"\"\"\n",
    "        if self.hparams.compile and stage == \"fit\":\n",
    "            self.net = torch.compile(self.net)\n",
    "\n",
    "    def configure_optimizers(self) -> Dict[str, Any]:\n",
    "        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
    "\n",
    "        Examples:\n",
    "            https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers\n",
    "\n",
    "        :return: A dict containing the configured optimizers and learning-rate schedulers to be used for training.\n",
    "        \"\"\"\n",
    "        optimizer = self.hparams.optimizer(params=self.trainer.model.parameters())\n",
    "        if self.hparams.scheduler is not None:\n",
    "            scheduler = self.hparams.scheduler(optimizer=optimizer)\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val/loss\",\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"frequency\": 1,\n",
    "                },\n",
    "            }\n",
    "        return {\"optimizer\": optimizer}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _ = MetalAILitModule(None, None, None, None, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /Users/moustholmes/Projects/METAL-AI/configs/model/transformer_encoder_model.yaml\n",
    "_target_: src.models.metalAI_module.MetalAILitModule\n",
    "\n",
    "target_name: 'converged'\n",
    "\n",
    "model:\n",
    "  _target_: src.models.components.Transformer_encoder_model.simple_transformer_encoder_model\n",
    "  csf_encoder: #${CSF_encoders.simple_csf_encoder}  # Reference the entire encoder config\n",
    "    _target_: src.models.components.CSF_encoders.simple_CSF_encoder #/home/projects/ku_00258/people/mouhol/METAL-AI/src/models/components/CSF_encoder.py\n",
    "    output_size: 4\n",
    "  d_model: 32 #${model.CSF_encoders.simple_csf_encoder}  # Directly use the encoder's output_size\n",
    "  nhead: 2\n",
    "  dim_forward: 16\n",
    "  num_layers: 4\n",
    "  output_size: 1\n",
    "  dropout: 0.00\n",
    "  output_activation:\n",
    "    _target_: torch.nn.Sigmoid\n",
    "    \n",
    "\n",
    "loss_fn:\n",
    "  _target_: src.loss_functions.loss_function_wrappers.LossFuncMaskWrapper # torch.nn.MSELoss\n",
    "  loss_fn: \n",
    "    _target_: torch.nn.BCELoss\n",
    "    reduction: sum\n",
    "\n",
    "optimizer:\n",
    "  _target_: torch.optim.Adam\n",
    "  _partial_: true\n",
    "  lr: 0.001\n",
    "  weight_decay: 0.1\n",
    "\n",
    "scheduler:\n",
    "  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "  _partial_: true\n",
    "  T_0: 5\n",
    "  T_mult: 2\n",
    "  eta_min: 0.\n",
    "\n",
    "# scheduler:\n",
    "#   _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "#   _partial_: true\n",
    "#   mode: min\n",
    "#   factor: 0.1\n",
    "#   patience: 3\n",
    "\n",
    "\n",
    "# compile model for faster training with pytorch 2.0\n",
    "compile: false\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightningmodule = instantiate(cfg_train.model)\n",
    "# pprint(cfg_train.model.model)\n",
    "print(OmegaConf.to_yaml(cfg_train.model))\n",
    "print()\n",
    "print(lightningmodule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "import pickle\n",
    "\n",
    "trainer = Trainer(max_epochs=5)\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "lightningmodule = instantiate(cfg_train.model)\n",
    "\n",
    "trainer.fit(model= lightningmodule, datamodule=datamodule)\n",
    "trainer.test(model= lightningmodule, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloaders = datamodule.test_dataloader()\n",
    "test_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/callbacks/metric_loggers.py\n",
    "import torchmetrics\n",
    "from lightning import LightningModule, Trainer\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from torchmetrics.wrappers import MetricTracker\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "\n",
    "\n",
    "class CSFMetricsLogger(Callback):\n",
    "    \"\"\"Callback for logging classification metrics using torchmetrics.\n",
    "    \n",
    "    This callback logs metrics at the end of each training, validation, and test batch.\n",
    "    The metrics are logged to the PyTorch Lightning module's logger.\n",
    "    \n",
    "    Args:\n",
    "        metrics (torchmetrics.MetricCollection): A collection of metrics to log.\"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self,):\n",
    "        classification_metrics = torchmetrics.MetricCollection([BinaryAccuracy(), BinaryPrecision(), BinaryRecall(), BinaryF1Score()])\n",
    "        self.train_metrics = classification_metrics.clone(prefix=\"train/\")\n",
    "        self.val_metrics = classification_metrics.clone(prefix=\"val/\")\n",
    "        self.test_metrics = classification_metrics.clone(prefix=\"test/\")\n",
    "        prev_batch_size = 0\n",
    "\n",
    "    # def log_metrics(self, pl_module, metrics, preds, targets):\n",
    "    #     \"\"\"Log the given metrics to the PyTorch Lightning module's logger.\n",
    "\n",
    "    #     Args:\n",
    "    #         pl_module (LightningModule): The Lightning module being trained.\n",
    "    #         metrics (torchmetrics.MetricCollection): The metrics to log.\n",
    "    #         preds (torch.Tensor): The predicted outputs.\n",
    "    #         targets (torch.Tensor): The ground truth targets.\n",
    "    #     \"\"\"\n",
    "\n",
    "    #     pl_module.log_dict(\n",
    "    #         metrics(preds, targets),\n",
    "    #         on_step=False,\n",
    "    #         on_epoch=True,\n",
    "    #         prog_bar=True,\n",
    "    #     )\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        print(outputs[\"batch_shape\"],outputs[\"batch_shape\"][1])\n",
    "        print(outputs[\"preds\"], outputs[\"targets\"])\n",
    "        self.train_metrics.update( outputs[\"preds\"], outputs[\"targets\"])\n",
    "        if outputs[\"batch_shape\"][1] != self.prev_batch_size:\n",
    "            pl_module.log_dict(self.train_metrics.compute())\n",
    "            self.train_metrics.reset()\n",
    "\n",
    "        self.prev_batch_size = outputs[\"batch_shape\"][1]\n",
    "            \n",
    "        # self.log_metrics(pl_module, self.train_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "    ):\n",
    "        self.val_metrics.update( outputs[\"preds\"], outputs[\"targets\"])\n",
    "        if outputs[\"batch_shape\"][1] != self.prev_batch_size:\n",
    "            pl_module.log_dict(self.val_metrics.compute())\n",
    "            self.val_metrics.reset()\n",
    "        self.prev_batch_size = outputs[\"batch_shape\"][1]\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        self.test_metrics.update( outputs[\"preds\"], outputs[\"targets\"])\n",
    "        if outputs[\"batch_shape\"][1] != self.prev_batch_size:\n",
    "            pl_module.log_dict(self.test_metrics.compute())\n",
    "            self.test_metrics.reset()\n",
    "        self.prev_batch_size = outputs[\"batch_shape\"][1]\n",
    "\n",
    "class RegressionMetricsLogger(Callback):\n",
    "    \"\"\"Callback for logging training, validation, and test metrics using torchmetrics.\n",
    "\n",
    "    This callback logs metrics at the end of each training, validation, and test batch.\n",
    "    The metrics are logged to the PyTorch Lightning module's logger.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):# metrics: torchmetrics.MetricCollection\n",
    "\n",
    "        regression_metrics = torchmetrics.MetricCollection([MeanAbsoluteError(),])# MeanAbsolutePercentageError()\n",
    "        self.train_metrics = regression_metrics.clone(prefix=\"train/\")\n",
    "        self.val_metrics = regression_metrics.clone(prefix=\"val/\")\n",
    "        self.test_metrics = regression_metrics.clone(prefix=\"test/\")\n",
    "\n",
    "    def log_metrics(self, pl_module, metrics, preds, targets):\n",
    "        \"\"\"Log the given metrics to the PyTorch Lightning module's logger.\n",
    "\n",
    "        Args:\n",
    "            pl_module (LightningModule): The Lightning module being trained.\n",
    "            metrics (torchmetrics.MetricCollection): The metrics to log.\n",
    "            preds (torch.Tensor): The predicted outputs.\n",
    "            targets (torch.Tensor): The ground truth targets.\n",
    "        \"\"\"\n",
    "\n",
    "        pl_module.log_dict(\n",
    "            metrics(preds, targets),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def setup(self, trainer, pl_module, stage):\n",
    "        self.train_metrics.to(pl_module.device)\n",
    "        self.val_metrics.to(pl_module.device)\n",
    "        self.test_metrics.to(pl_module.device)\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        self.log_metrics(pl_module, self.train_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "    ):\n",
    "        self.log_metrics(pl_module, self.val_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        self.log_metrics(pl_module, self.test_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "class GaussianNLLMetricsLogger(Callback):\n",
    "    \"\"\"Callback for logging training, validation, and test metrics using torchmetrics.\n",
    "\n",
    "    This callback logs metrics at the end of each training, validation, and test batch.\n",
    "    The metrics are logged to the PyTorch Lightning module's logger.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):# metrics: torchmetrics.MetricCollection\n",
    "\n",
    "        regression_metrics = torchmetrics.MetricCollection([MeanAbsoluteError(),])# MeanAbsolutePercentageError()\n",
    "        # variance_metrics = torchmetrics.MetricCollection([MeanAbsoluteError(),])# MeanAbsolutePercentageError()\n",
    "        self.train_metrics = regression_metrics.clone(prefix=\"train/\")\n",
    "        self.train_variance = torchmetrics.MeanMetric()\n",
    "        self.val_metrics = regression_metrics.clone(prefix=\"val/\")\n",
    "        self.val_variance = torchmetrics.MeanMetric()\n",
    "        self.test_metrics = regression_metrics.clone(prefix=\"test/\")\n",
    "        self.test_variance = torchmetrics.MeanMetric()\n",
    "\n",
    "    def log_metrics(self, pl_module, metrics, preds, targets):\n",
    "        \"\"\"Log the given metrics to the PyTorch Lightning module's logger.\n",
    "\n",
    "        Args:\n",
    "            pl_module (LightningModule): The Lightning module being trained.\n",
    "            metrics (torchmetrics.MetricCollection): The metrics to log.\n",
    "            preds (torch.Tensor): The predicted outputs.\n",
    "            targets (torch.Tensor): The ground truth targets.\n",
    "        \"\"\"\n",
    "\n",
    "        pl_module.log_dict(\n",
    "            metrics(preds, targets),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def setup(self, trainer, pl_module, stage):\n",
    "        self.train_metrics.to(pl_module.device)\n",
    "        self.train_variance.to(pl_module.device)\n",
    "        self.val_metrics.to(pl_module.device)\n",
    "        self.val_variance.to(pl_module.device)\n",
    "        self.test_metrics.to(pl_module.device)\n",
    "        self.test_variance.to(pl_module.device)\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.val_metrics.reset()\n",
    "        self.val_variance.reset()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        mask = outputs[\"mask\"]\n",
    "        mean = outputs[\"preds\"][:,:,0][mask]\n",
    "        variance = outputs[\"preds\"][:,:,1][mask]\n",
    "        targets = outputs[\"targets\"][mask]\n",
    "\n",
    "\n",
    "        pl_module.log(\"train/mean_variace\", self.test_variance(variance), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log_metrics(pl_module, self.train_metrics, mean, targets)\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "    ):  \n",
    "        mask = outputs[\"mask\"]\n",
    "        mean = outputs[\"preds\"][:,:,0][mask]\n",
    "        variance = outputs[\"preds\"][:,:,1][mask]\n",
    "        targets = outputs[\"targets\"][mask]\n",
    "\n",
    "        pl_module.log(\"val/mean_variace\", self.val_variance(variance), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log_metrics(pl_module, self.val_metrics, mean, targets)\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        mask = outputs[\"mask\"]\n",
    "        mean = outputs[\"preds\"][:,:,0][mask]\n",
    "        variance = outputs[\"preds\"][:,:,1][mask]\n",
    "        targets = outputs[\"targets\"][mask]\n",
    "\n",
    "        pl_module.log(\"test/mean_variace\", self.test_variance(variance), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log_metrics(pl_module, self.test_metrics, mean, targets)\n",
    "\n",
    "class ClassificationMetricsLogger(Callback):\n",
    "    \"\"\"Callback for logging training, validation, and test metrics using torchmetrics.\n",
    "\n",
    "    This callback logs metrics at the end of each training, validation, and test batch.\n",
    "    The metrics are logged to the PyTorch Lightning module's logger.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):# metrics: torchmetrics.MetricCollection\n",
    "\n",
    "        classification_metrics = torchmetrics.MetricCollection([BinaryAccuracy(), BinaryPrecision(), BinaryRecall(), BinaryF1Score()])\n",
    "        self.train_metrics = classification_metrics.clone(prefix=\"train/\")\n",
    "        self.val_metrics = classification_metrics.clone(prefix=\"val/\")\n",
    "        self.test_metrics = classification_metrics.clone(prefix=\"test/\")\n",
    "\n",
    "    def log_metrics(self, pl_module, metrics, preds, targets):\n",
    "        \"\"\"Log the given metrics to the PyTorch Lightning module's logger.\n",
    "\n",
    "        Args:\n",
    "            pl_module (LightningModule): The Lightning module being trained.\n",
    "            metrics (torchmetrics.MetricCollection): The metrics to log.\n",
    "            preds (torch.Tensor): The predicted outputs.\n",
    "            targets (torch.Tensor): The ground truth targets.\n",
    "        \"\"\"\n",
    "\n",
    "        pl_module.log_dict(\n",
    "            metrics(preds, targets),\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def setup(self, trainer, pl_module, stage):\n",
    "        self.train_metrics.to(pl_module.device)\n",
    "        self.val_metrics.to(pl_module.device)\n",
    "        self.test_metrics.to(pl_module.device)\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        self.log_metrics(pl_module, self.train_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "        self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "    ):\n",
    "        self.log_metrics(pl_module, self.val_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "    def on_test_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        self.log_metrics(pl_module, self.test_metrics, outputs[\"preds\"], outputs[\"targets\"])\n",
    "\n",
    "\n",
    "class BestMetricsLogger(ClassificationMetricsLogger):\n",
    "    \"\"\"Callback for logging and tracking the best validation metrics using torchmetrics\n",
    "    MetricTracker.\n",
    "\n",
    "    This callback extends MetricLogger to track the best validation metrics over epochs.\n",
    "    It logs the best metrics observed so far at the end of each validation epoch.\n",
    "\n",
    "    Args:\n",
    "        metrics (torchmetrics.MetricCollection): A collection of metrics to log and track.\n",
    "\n",
    "    Attributes:\n",
    "        val_metrics (torchmetrics.MetricTracker): Metrics for tracking the best validation performance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, metrics: torchmetrics.MetricCollection):\n",
    "        super().__init__(metrics)\n",
    "        self.val_metrics = MetricTracker(\n",
    "            metrics.clone(prefix=\"val/\"),\n",
    "            maximize=[metric.higher_is_better for _, metric in metrics.items()],\n",
    "        )\n",
    "\n",
    "    def on_validation_epoch_start(self, trainer, pl_module):\n",
    "        self.val_metrics.increment()\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        pl_module.log_dict(\n",
    "            {f\"{k}_best\": v for k, v in self.val_metrics.best_metric().items()},\n",
    "            prog_bar=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_train = compose(config_name='train',)\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "lightningmodule = instantiate(cfg_train.model)\n",
    "\n",
    "trainer = Trainer(max_epochs=2, callbacks=[ClassificationMetricsLogger()], accelerator=\"gpu\")\n",
    "trainer.fit(model= lightningmodule, datamodule=datamodule, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_train = compose(config_name='train', overrides=['experiment=effect_gaussian_nll'])\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "lightningmodule = instantiate(cfg_train.model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    limit_train_batches=200,\n",
    "    limit_val_batches=200,\n",
    "    limit_test_batches=200,\n",
    "    callbacks=[GaussianNLLMetricsLogger()], \n",
    "    accelerator=\"gpu\"\n",
    "    )\n",
    "trainer.fit(model= lightningmodule, datamodule=datamodule, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile /Users/moustholmes/Projects/METAL-AI/src/callbacks/save_test_inference_to_dict.py\n",
    "\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class SaveTestInferenceToDict(Callback):\n",
    "    \"\"\"Callback for saving test inference to a dictionary.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): path to save the dictionary.\n",
    "\n",
    "    Attributes:\n",
    "        save_dir (str):  path to save the dictionary.\n",
    "        pred_dict (Dict): Dict used to save predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_dir: str, filename: str = 'results'):\n",
    "        self.save_dir = save_dir\n",
    "        self.filename = filename\n",
    "\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        self.pred_dict = {}\n",
    "\n",
    "    def on_test_batch_end(\n",
    "            self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "        ):\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        mask = outputs['mask']\n",
    "        preds = outputs['preds'][mask]\n",
    "        targets = outputs['targets'][mask]\n",
    "        \n",
    "        \n",
    "        # print(mask.shape)\n",
    "        # print(csf.shape)\n",
    "        # print(csf.unsqueeze(1).shape)\n",
    "        \n",
    "        # print(csf)\n",
    "        excitations = batch[\"excitations\"][mask]\n",
    "        # print(excitations)\n",
    "        # print(excitations[0])\n",
    "        # print( mask.sum().item() )\n",
    "        \n",
    "        n = batch[\"converged\"].shape[-1]\n",
    "        \n",
    "        # print(csf.repeat(n,1,1,1).shape)\n",
    "        # print(csf.repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)].shape)\n",
    "        # print(csf.repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)])\n",
    "        # print(csf.repeat(n,1,1,1)[mask.unsqueeze(0).repeat(n, 1, 1)])\n",
    "        n_protons = batch[\"n_protons\"].unsqueeze(1).repeat(1,n)[mask]\n",
    "        # print(csf.unsqueeze(1).repeat(1,1,n)[mask.unsqueeze(-1)])\n",
    "        n_electrons = batch[\"n_electrons\"].unsqueeze(1).repeat(1,n)[mask]\n",
    "        csf = batch[\"excitations\"].repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)]\n",
    "\n",
    "        for i in range(len(targets)):\n",
    "            ion_key = (n_protons[i].item(), n_electrons[i].item())\n",
    "            # print(ion_key)\n",
    "            csf_key = tuple(map(tuple, csf[i].cpu().numpy()))\n",
    "            # print(csf_key)\n",
    "\n",
    "            if ion_key not in self.pred_dict:\n",
    "                self.pred_dict[ion_key] = {}\n",
    "            \n",
    "            if csf_key not in self.pred_dict[ion_key]:\n",
    "                self.pred_dict[ion_key][csf_key] = {}\n",
    "\n",
    "            self.pred_dict[ion_key][csf_key]['preds'] = preds[i].cpu().numpy()\n",
    "            self.pred_dict[ion_key][csf_key]['targets'] = targets[i].cpu().numpy()\n",
    "            self.pred_dict[ion_key][csf_key]['excitation'] = excitations[i].cpu().numpy()\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        with open(self.save_dir+f'/{self.filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.pred_dict, f)\n",
    "\n",
    "\n",
    "class GaussianNLLSaveTestInferenceToDict(Callback):\n",
    "    \"\"\"Callback for saving test inference to a dictionary.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): path to save the dictionary.\n",
    "\n",
    "    Attributes:\n",
    "        save_dir (str):  path to save the dictionary.\n",
    "        pred_dict (Dict): Dict used to save predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, save_dir: str, filename: str = 'results'):\n",
    "        self.save_dir = save_dir\n",
    "        self.filename = filename\n",
    "\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        self.pred_dict = {}\n",
    "\n",
    "    def on_test_batch_end(\n",
    "            self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0\n",
    "        ):\n",
    "        \"\"\"Perform a single test step on a batch of data from the test set.\n",
    "\n",
    "        :param batch: A batch of data (a tuple) containing the input tensor of images and target\n",
    "            labels.\n",
    "        :param batch_idx: The index of the current batch.\n",
    "        \"\"\"\n",
    "        mask = outputs['mask']\n",
    "        mean = outputs['preds'][:,:,0][mask]\n",
    "        variance = outputs['preds'][:,:,1][mask]\n",
    "        # preds = outputs['preds'][mask]\n",
    "        targets = outputs['targets'][mask]\n",
    "        \n",
    "        \n",
    "        # print(mask.shape)\n",
    "        # print(csf.shape)\n",
    "        # print(csf.unsqueeze(1).shape)\n",
    "        \n",
    "        # print(csf)\n",
    "        excitations = batch[\"excitations\"][mask]\n",
    "        # print(excitations)\n",
    "        # print(excitations[0])\n",
    "        # print( mask.sum().item() )\n",
    "        \n",
    "        n = batch[\"converged\"].shape[-1]\n",
    "        \n",
    "        # print(csf.repeat(n,1,1,1).shape)\n",
    "        # print(csf.repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)].shape)\n",
    "        # print(csf.repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)])\n",
    "        # print(csf.repeat(n,1,1,1)[mask.unsqueeze(0).repeat(n, 1, 1)])\n",
    "        n_protons = batch[\"n_protons\"].unsqueeze(1).repeat(1,n)[mask]\n",
    "        # print(csf.unsqueeze(1).repeat(1,1,n)[mask.unsqueeze(-1)])\n",
    "        n_electrons = batch[\"n_electrons\"].unsqueeze(1).repeat(1,n)[mask]\n",
    "        csf = batch[\"excitations\"].repeat(n,1,1,1).view(-1, n, 2)[mask.view(-1)]\n",
    "\n",
    "        for i in range(len(mean)):\n",
    "            ion_key = (n_protons[i].item(), n_electrons[i].item())\n",
    "            # print(ion_key)\n",
    "            csf_key = tuple(map(tuple, csf[i].cpu().numpy()))\n",
    "            # print(csf_key)\n",
    "\n",
    "            if ion_key not in self.pred_dict:\n",
    "                self.pred_dict[ion_key] = {}\n",
    "            \n",
    "            if csf_key not in self.pred_dict[ion_key]:\n",
    "                self.pred_dict[ion_key][csf_key] = {}\n",
    "\n",
    "            self.pred_dict[ion_key][csf_key]['mean'] = mean[i].cpu().numpy()\n",
    "            self.pred_dict[ion_key][csf_key]['variance'] = variance[i].cpu().numpy()\n",
    "            self.pred_dict[ion_key][csf_key]['targets'] = targets[i].cpu().numpy()\n",
    "            self.pred_dict[ion_key][csf_key]['excitation'] = excitations[i].cpu().numpy()\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        with open(self.save_dir+f'/{self.filename}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.pred_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "lightningmodule = instantiate(cfg_train.model)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,         \n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    "    limit_test_batches=200,\n",
    "    callbacks=[GaussianNLLSaveTestInferenceToDict('/Users/moustholmes/Projects/METAL-AI', name='gaussian_nll_results_test')], \n",
    "    # accelerator=\"gpu\"\n",
    "    )\n",
    "trainer.fit(model= lightningmodule, datamodule=datamodule, )\n",
    "trainer.test(model= lightningmodule, datamodule=datamodule, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import Trainer\n",
    "\n",
    "cfg_train = compose(config_name='train', overrides=['experiment=effect_gaussian_nll'])\n",
    "datamodule = instantiate(cfg_train.data)\n",
    "lightningmodule = instantiate(cfg_train.model)\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,         \n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    "    # limit_test_batches=6,  \n",
    "    callbacks=[GaussianNLLSaveTestInferenceToDict('/Users/moustholmes/Projects/METAL-AI', name='gaussian_nll_results_test')], \n",
    "    # accelerator=\"gpu\"\n",
    "    )\n",
    "trainer.fit(model= lightningmodule, datamodule=datamodule, )\n",
    "trainer.test(model= lightningmodule, datamodule=datamodule, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
